{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634268e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DATASET_PERIOD\"] = \"50\"\n",
    "os.environ[\"PMODE\"] = \"pmode_0002\" # same as jetson orin\n",
    "os.environ[\"STREVAL_TRAIN\"] = \"1\"\n",
    "os.environ[\"FINE_GRAINED_EVAL\"] = \"0\"\n",
    "os.chdir(\"/root/shared/Anytime-Lidar/tools\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "import math\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pyquaternion import Quaternion\n",
    "from IPython.display import clear_output\n",
    "import res_pred_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5316a8-85e0-4b00-b175-ea4b44970664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "\n",
    "token_to_scene = {}\n",
    "token_to_scene_name = {}\n",
    "token_to_ts = {}\n",
    "try:\n",
    "    with open('token_to_pos.json', 'r') as handle:\n",
    "        token_to_pose = json.load(handle)\n",
    "\n",
    "    for k, v in token_to_pose.items():\n",
    "        cst, csr, ept, epr = v['cs_translation'],  v['cs_rotation'], \\\n",
    "                v['ep_translation'], v['ep_rotation']\n",
    "        # convert time stamps to seconds\n",
    "        # 3 4 3 4\n",
    "        token_to_pose[k] = torch.tensor((*cst, *csr, *ept, *epr), dtype=torch.float)\n",
    "        token_to_ts[k] = int(v['timestamp'])\n",
    "        token_to_scene[k] = v['scene']\n",
    "        token_to_scene_name[k] = v['scene_name']\n",
    "except:\n",
    "    print(\"Couldn't find token_to_pos.json, not loading it.\")\n",
    "    pass\n",
    "\n",
    "nusc = NuScenes(version=\"v1.0-trainval\",\n",
    "                dataroot=\"../data/nuscenes/v1.0-trainval\",\n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81606eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(res_pred_utils)\n",
    "\n",
    "# CONSTANTS\n",
    "with open('resolution_dataset.pkl', 'rb') as f:\n",
    "    io_dict = pickle.load(f)\n",
    "    print(io_dict['fields'])\n",
    "    io_tuples = io_dict['data']\n",
    "\n",
    "# Each tuple has: 'coords', 'features', 'resolution', 'sample_tkn'\n",
    "# remove duplicates first\n",
    "scores = [tuple(io_tpl[1][:, 6].ravel()) for io_tpl in io_tuples]\n",
    "mask = np.ones(len(scores), dtype=bool)\n",
    "scores_set = set()\n",
    "for i, scr in enumerate(scores):\n",
    "    if scr in scores_set:\n",
    "        mask[i] = False\n",
    "    else:\n",
    "        scores_set.add(scr)\n",
    "\n",
    "io_tuples = [io_tpl for m, io_tpl in zip(mask, io_tuples) if m]\n",
    "print('Number of samples in dataset after removing duplicates:', len(io_tuples))\n",
    "\n",
    "#NOTE diving by two to make input smaller\n",
    "# all_coords = [torch.from_numpy(t[0][:, :2]).long() for t in io_tuples]\n",
    "# cmax = torch.tensor([c.max() for c in all_coords]).max()\n",
    "# assert cmax < 128\n",
    "# cmin = torch.tensor([c.min() for c in all_coords]).min()\n",
    "# assert cmin >= 0\n",
    "# print('Min and max coords:', cmin, cmax)\n",
    "\n",
    "res_exec_times_sec = [0.247, 0.147, 0.107, 0.91, 0.77]\n",
    "# res_exec_times_sec = [0.110, 0.105, 0.100]\n",
    "\n",
    "use_annos = True\n",
    "visualize = True\n",
    "# 750 and 1500 are nice\n",
    "res_selections = np.zeros(len(res_exec_times_sec))\n",
    "same_as_heuristic = 0\n",
    "exec_times = []\n",
    "for i in range(0, len(io_tuples), 50 if visualize else 1):\n",
    "    io_tpl = io_tuples[i]\n",
    "    coords, features, res, sample_tkn = io_tpl\n",
    "\n",
    "    sample = nusc.get('sample', sample_tkn)\n",
    "\n",
    "    if not use_annos:\n",
    "        t1 = time.time()\n",
    "        scores_mask = features[:, 6] > 0.5\n",
    "        coords = coords[scores_mask]\n",
    "        features = features[scores_mask]\n",
    "\n",
    "        prev_sample_tkn = sample['prev']\n",
    "        if prev_sample_tkn != '':\n",
    "            egovel = res_pred_utils.get_2d_egovel(\n",
    "                                    token_to_ts[prev_sample_tkn],\n",
    "                                    token_to_pose[prev_sample_tkn],\n",
    "                                    token_to_ts[sample_tkn],\n",
    "                                    token_to_pose[sample_tkn])\n",
    "        else:\n",
    "            egovel = np.zeros(2)\n",
    "    \n",
    "        bboxes = np.zeros((features.shape[0], 9))\n",
    "        bboxes[:, :2] = coords - 57.6\n",
    "        # bboxes[:, 3:6] = features[:, :3] * np.array([40., 10., 15.])\n",
    "        # bboxes[:, 6] = features[:, 3] * 3.14\n",
    "        bboxes[:, 7:] = features[:, 4:6] * 15.0\n",
    "        pred_dict = {\n",
    "            'pred_boxes': torch.from_numpy(bboxes),\n",
    "            'pred_scores': torch.from_numpy(features[:, 6]).float(),\n",
    "            'pred_labels': torch.from_numpy(features[:, 7] * 10).int(),\n",
    "        }\n",
    "        \n",
    "        chosen_res = res_pred_utils.pick_best_resolution(res_exec_times_sec, egovel, pred_dict)\n",
    "        res_selections[chosen_res] += 1\n",
    "        t2 = time.time()\n",
    "        exec_times.append(t2-t1)\n",
    "    \n",
    "        # print(chosen_res, res)\n",
    "        same_as_heuristic += (chosen_res == res)\n",
    "        \n",
    "        if i % 1000 == 0 and i > 0:\n",
    "            print('res selections:', res_selections)\n",
    "            print('res selections perc:', res_selections / res_selections.sum())\n",
    "            print('Exec time:', round(sum(exec_times)/i * 1000,2), 'ms')\n",
    "\n",
    "    # if i == 100:\n",
    "    #     break\n",
    "\n",
    "    if visualize:\n",
    "        sample = nusc.get('sample', sample_tkn)\n",
    "        sensor = 'LIDAR_TOP'\n",
    "        lidar_data = nusc.get('sample_data', sample['data'][sensor])\n",
    "        _, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "        nusc.render_sample_data(lidar_data['token'], nsweeps=1, axes_limit=60,\n",
    "                                use_flat_vehicle_coordinates=False, underlay_map=False,\n",
    "                                ax=ax, verbose=False)\n",
    "\n",
    "        if use_annos:\n",
    "            ep, egovel = res_pred_utils.get_egopose_and_egovel(nusc, sample_tkn)\n",
    "            cs = nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])\n",
    "            boxes = nusc.get_boxes(sample['data'][sensor])\n",
    "            for box in boxes:\n",
    "                box.velocity = nusc.box_velocity(box.token)\n",
    "                # Move box to ego vehicle coord system\n",
    "                box.translate(-np.array(ep['translation']))\n",
    "                box.rotate(Quaternion(ep['rotation']).inverse)\n",
    "        \n",
    "                #  Move box to sensor coord system\n",
    "                box.translate(-np.array(cs['translation']))\n",
    "                box.rotate(Quaternion(cs['rotation']).inverse)\n",
    "            # print(dir(boxes[0]))\n",
    "            print([b.name for b in boxes])\n",
    "            coords = [box.center for box in boxes]\n",
    "            velos = [box.velocity for box in boxes]\n",
    "        else:\n",
    "            coords = bboxes[:, :2]\n",
    "            velos = bboxes[:, 7:9]\n",
    "        \n",
    "        for vel, coord in zip(velos, coords):\n",
    "            # Relative velos\n",
    "            ax.arrow(coord[0], coord[1], vel[0] - egovel[0], vel[1] - egovel[1],\n",
    "            #ax.arrow(coord[0], coord[1], vel[0], vel[1],\n",
    "                 head_width=0.9, head_length=0.7, fc='red', ec='red')\n",
    "    \n",
    "        # Egovel\n",
    "        ax.arrow(0, 0, egovel[0], egovel[1],\n",
    "                 head_width=0.9, head_length=0.7, fc='red', ec='red')\n",
    "        \n",
    "        plt.show()\n",
    "        break\n",
    "        input('Waiting user...')\n",
    "        clear_output()\n",
    "print('res selections:', res_selections)\n",
    "print('res selections perc:', res_selections / res_selections.sum())\n",
    "print('same_as_heuristic:', same_as_heuristic)\n",
    "print('same_as_heuristic perc:', same_as_heuristic / len(io_tuples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
