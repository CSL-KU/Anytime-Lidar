{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e79a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/root/shared/Anytime-Lidar/tools\")\n",
    "os.environ[\"DATASET_PERIOD\"] = \"50\"\n",
    "os.environ[\"PMODE\"] = \"pmode_0003\" # same as jetson orin\n",
    "os.environ[\"CALIBRATION\"] = \"0\"\n",
    "os.environ[\"PCDET_PATH\"] = \"/root/shared/Anytime-Lidar\"\n",
    "\n",
    "import _init_path\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "from eval_utils import eval_utils\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.utils import common_utils\n",
    "from pcdet.models.model_utils.tensorrt_utils.trtwrapper import TRTWrapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import res_pred_utils\n",
    "import nuscenes\n",
    "import importlib\n",
    "# import numba\n",
    "import concurrent.futures\n",
    "\n",
    "def get_dataset(cfg):\n",
    "    log_file = './tmp_results/log_eval_%s' % datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    log_file = log_file + str(np.random.randint(0, 9999)) + '.txt'\n",
    "    logger = common_utils.create_logger(log_file, rank=0)\n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, batch_size=1,\n",
    "        dist=False, workers=0, logger=logger, training=False\n",
    "    )\n",
    "\n",
    "    return logger, test_set, test_loader, sampler\n",
    "\n",
    "def calc_tail_ms(cur_time_point_ms, data_period_ms):\n",
    "    return cur_time_point_ms - math.floor(cur_time_point_ms / data_period_ms) * data_period_ms\n",
    "\n",
    "def build_model():\n",
    "    cfg_file = \"./cfgs/nuscenes_models/pillar01_015_02_024_03_valor.yaml\"\n",
    "    cfg_from_yaml_file(cfg_file, cfg)\n",
    "    \n",
    "    set_cfgs = ['MODEL.METHOD', '0', 'MODEL.DEADLINE_SEC', '100.0', 'MODEL.DENSE_HEAD.NAME', 'CenterHeadInf',\n",
    "                'OPTIMIZATION.BATCH_SIZE_PER_GPU', '1']\n",
    "    cfg_from_list(set_cfgs, cfg)\n",
    "    logger, test_set, test_loader, sampler = get_dataset(cfg)\n",
    "    print(f'Loaded dataset with {len(test_set)} samples')\n",
    "\n",
    "    ckpt_file=\"../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth\"\n",
    "\n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "    model.load_params_from_file(filename=ckpt_file, logger=logger, to_cpu=False)\n",
    "    # model.pre_hook_handle.remove()\n",
    "    # model.post_hook_handle.remove()\n",
    "    model.eval() # should be run with @torch.no_grad\n",
    "    model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "@torch.jit.script\n",
    "def move_bounding_boxes(bboxes, egovel, time_diffs_sec):\n",
    "    outp_shape = (time_diffs_sec.shape[0], bboxes.shape[0], bboxes.shape[1])\n",
    "    outp_bboxes = torch.empty(outp_shape, dtype=bboxes.dtype)\n",
    "    outp_bboxes[:, :, 2:] = bboxes[:, 2:]\n",
    "\n",
    "    for t in range(time_diffs_sec.shape[0]):\n",
    "        outp_bboxes[t, :, :2] = bboxes[:, :2] + (bboxes[:, 7:9] - egovel) * time_diffs_sec[t]\n",
    "\n",
    "    return outp_bboxes\n",
    "\n",
    "def run_test(model, resolution_idx, streaming=True, forecasting=False, sched_period_ms=2000):\n",
    "    print('***********************')\n",
    "    print(f'***RESOLUTION INDEX {resolution_idx}**')\n",
    "    print('***********************')\n",
    "\n",
    "    data_period_ms = int(os.environ[\"DATASET_PERIOD\"])\n",
    "    num_samples = len(model.dataset)\n",
    "\n",
    "    cur_sample_idx = 0\n",
    "    sim_cur_time_ms = 0.\n",
    "    last_exec_time_ms = 100.\n",
    "    target_sched_time_ms = 0.\n",
    "    sampled_dets = [None] * num_samples\n",
    "    exec_times_ms = []\n",
    "    # sample_tokens = []\n",
    "    resolution_stats = [0] * model.num_res\n",
    "\n",
    "    model.calibrate()\n",
    "    do_res_sched = (resolution_idx == -1)\n",
    "    model.res_idx = 0 if do_res_sched else resolution_idx\n",
    "\n",
    "    if do_res_sched:\n",
    "        trt_path = f\"./deploy_files/trt_engines/pmode_0000/resolution_pred_mdl.engine\"\n",
    "        print('Trying to load trt engine at', trt_path)\n",
    "        res_pred_trt = TRTWrapper(trt_path, ['objcount_and_egovel'], ['res_scores'])\n",
    "        res_pred_out_buf = None\n",
    "\n",
    "    model.prev_scene_token = model.token_to_scene[model.dataset.infos[cur_sample_idx]['token']]\n",
    "    with alive_bar(num_samples, force_tty=True, max_cols=160, manual=True) as bar:\n",
    "        while cur_sample_idx < num_samples:\n",
    "            # Check if we are in a new scene, reset if we are\n",
    "            if streaming:\n",
    "                potential_sample_tkn = model.dataset.infos[cur_sample_idx]['token']\n",
    "                scene_token = model.token_to_scene[potential_sample_tkn]\n",
    "                if model.prev_scene_token != scene_token:\n",
    "                    target_sched_time_ms = 0.\n",
    "                    while model.prev_scene_token != scene_token:\n",
    "                        cur_sample_idx -= 1\n",
    "                        potential_sample_tkn = model.dataset.infos[cur_sample_idx]['token']\n",
    "                        scene_token = model.token_to_scene[potential_sample_tkn]\n",
    "                    cur_sample_idx += 1\n",
    "                    sim_cur_time_ms = cur_sample_idx * data_period_ms\n",
    "\n",
    "            with torch.no_grad():\n",
    "                lbd = model.latest_batch_dict # save bef its modified\n",
    "                pred_dicts, ret_dict = model([cur_sample_idx])\n",
    "\n",
    "            # Predict the execution time as if the DNN were to be executed on target platform\n",
    "            batch_dict = model.latest_batch_dict\n",
    "            num_points = batch_dict['points'].size(0)\n",
    "            num_voxels = np.array([batch_dict['bb3d_num_voxels']])\n",
    "            xlen = batch_dict['tensor_slice_inds'][1] - batch_dict['tensor_slice_inds'][0]\n",
    "            last_exec_time_ms = model.calibrators[model.res_idx].pred_exec_time_ms(\n",
    "               num_points, num_voxels, xlen)\n",
    "\n",
    "            sample_tkn = batch_dict['metadata'][0]['token']\n",
    "            if lbd is not None and not batch_dict['scene_reset']:\n",
    "                prev_sample_tkn = lbd['metadata'][0]['token']\n",
    "                egovel = res_pred_utils.get_2d_egovel(\n",
    "                        model.token_to_ts[prev_sample_tkn],\n",
    "                        model.token_to_pose[prev_sample_tkn],\n",
    "                        model.token_to_ts[sample_tkn],\n",
    "                        model.token_to_pose[sample_tkn])\n",
    "            else: # assume its zero\n",
    "                egovel = np.zeros(2)\n",
    "\n",
    "            exec_times_ms.append((sample_tkn, last_exec_time_ms))\n",
    "            if not streaming:\n",
    "                # sim_cur_time_ms += data_period_ms # unnecessary\n",
    "                sampled_dets[cur_sample_idx] = pred_dicts\n",
    "            else:\n",
    "                # the sampled_dets can be overwritten, which is okay\n",
    "                sim_cur_time_ms += last_exec_time_ms\n",
    "                num_to_forecast = 500 // data_period_ms\n",
    "                future_sample_inds = [(sim_cur_time_ms+(i*data_period_ms))//data_period_ms for i in range(1,num_to_forecast+1)]\n",
    "                future_sample_inds = torch.tensor([ind for ind in future_sample_inds if ind < num_samples]).int()\n",
    "                if forecasting: # NOTE consider the overhead here\n",
    "                    # Forecast for next 500 ms\n",
    "                    time_diffs_sec = (future_sample_inds * data_period_ms - (sim_cur_time_ms - last_exec_time_ms)) * 1e-3\n",
    "                    outp_bboxes_all = move_bounding_boxes(pred_dicts[0]['pred_boxes'], torch.from_numpy(egovel), time_diffs_sec)\n",
    "                    for outp_bboxes, sample_ind_f in zip(outp_bboxes_all, future_sample_inds.tolist()):\n",
    "                        forecasted_pd = {k : pred_dicts[0][k] for k in ('pred_scores', 'pred_labels')}\n",
    "                        forecasted_pd['pred_boxes'] = outp_bboxes\n",
    "                        sampled_dets[sample_ind_f] = [forecasted_pd]\n",
    "                else:\n",
    "                    for sample_ind_f in future_sample_inds.tolist():\n",
    "                        sampled_dets[sample_ind_f] = pred_dicts\n",
    "\n",
    "            if do_res_sched and sim_cur_time_ms >= target_sched_time_ms:\n",
    "                lbl_dist = torch.bincount(pred_dicts[0]['pred_labels'] - 1, minlength=10).float() / 100.0\n",
    "                inp_tensor = torch.tensor(lbl_dist.tolist() + [np.linalg.norm(egovel).item()/15.0], dtype=torch.float).unsqueeze(0)\n",
    "                inp_tensor[torch.isnan(inp_tensor)] = 0.\n",
    "                res_pred_out_buf = res_pred_trt({'objcount_and_egovel': inp_tensor.cuda()},\n",
    "                    res_pred_out_buf) \n",
    "                res_scores = res_pred_out_buf['res_scores'].cpu()\n",
    "\n",
    "                _, chosen_res = torch.max(res_scores, 1)\n",
    "                model.res_idx = chosen_res.item()\n",
    "\n",
    "                #NOTE I need to consider the sched time as well and add to sim cur time ms\n",
    "                target_sched_time_ms += sched_period_ms\n",
    "                resolution_stats[model.res_idx] += 1\n",
    "\n",
    "            #Dynamic scheduling\n",
    "            if streaming:\n",
    "                cur_tail = calc_tail_ms(sim_cur_time_ms, data_period_ms)\n",
    "                pred_finish_time = sim_cur_time_ms + last_exec_time_ms #NOTE I can also use mean exec time\n",
    "                next_tail = calc_tail_ms(pred_finish_time, data_period_ms)\n",
    "                if next_tail < cur_tail:\n",
    "                    # Sleep, extra 1 ms is added to make sure sleep time is enough\n",
    "                    sim_cur_time_ms += data_period_ms - cur_tail + 1\n",
    "\n",
    "                next_sample_idx = int(sim_cur_time_ms / data_period_ms)\n",
    "            else:\n",
    "                next_sample_idx = cur_sample_idx + 1\n",
    "\n",
    "            if cur_sample_idx == next_sample_idx:\n",
    "                print(f'ERROR, trying to process already processed sample {next_sample_idx}')\n",
    "\n",
    "            cur_sample_idx = next_sample_idx\n",
    "            bar(cur_sample_idx / num_samples)\n",
    "\n",
    "    if do_res_sched:\n",
    "        model.res_idx = -1\n",
    "    model.print_time_stats()\n",
    "    print('Resolution selection stats:')\n",
    "    print(resolution_stats)\n",
    "\n",
    "    exec_times_musec = {st:(et*1000) for st, et in exec_times_ms}\n",
    "\n",
    "    with open(f'tmp_results/detdata_res{model.res_idx}.pkl', 'wb') as f:\n",
    "        pickle.dump([sampled_dets, exec_times_musec, resolution_stats], f)\n",
    "\n",
    "    print(f'Sampled {len(sampled_dets)} objects')\n",
    "    return sampled_dets, exec_times_musec, resolution_stats\n",
    "\n",
    "def do_eval(sampled_objects, resolution_idx, dataset, exec_times_musec=None, dump_eval_dict=True, loaded_nusc=None):\n",
    "    #Convert them to openpcdet format\n",
    "    os.environ[\"RESOLUTION_IDX\"] = str(resolution_idx)\n",
    "\n",
    "    det_annos = []\n",
    "    num_ds_elems = len(dataset)\n",
    "    for i in range(num_ds_elems):\n",
    "        data_dict = dataset.get_metadata_dict(i)\n",
    "        for k, v in data_dict.items():\n",
    "            data_dict[k] = [v] # make it a batch dict\n",
    "        pred_dicts = sampled_objects[i]\n",
    "\n",
    "        if pred_dicts is None:\n",
    "            pred_dicts = [{\n",
    "                'pred_boxes': torch.empty((0, 9)),\n",
    "                'pred_scores': torch.empty(0),\n",
    "                'pred_labels': torch.empty(0, dtype=torch.long)\n",
    "            }]\n",
    "        data_dict['final_box_dicts'] = pred_dicts\n",
    "        det_annos += dataset.generate_prediction_dicts(\n",
    "            data_dict, data_dict['final_box_dicts'], dataset.class_names, output_path=None\n",
    "        )\n",
    "\n",
    "    #nusc_annos = {} # not needed but keep it anyway\n",
    "    streaming = (len(exec_times_musec) != len(dataset))\n",
    "    print('STREAMING EVAL' if streaming else 'OFFLINE EVAL')\n",
    "    result_str, result_dict = dataset.evaluation(\n",
    "        det_annos, dataset.class_names,\n",
    "        eval_metric='kitti', #model.model_cfg.POST_PROCESSING.EVAL_METRIC,\n",
    "        output_path='./tmp_results',\n",
    "        boxes_in_global_coords=False,\n",
    "        loaded_nusc=loaded_nusc,\n",
    "        det_elapsed_musec=None, #(None if streaming else exec_times_musec)\n",
    "    )\n",
    "\n",
    "    if dump_eval_dict:\n",
    "        eval_d = {\n",
    "                'cfg': cfg,\n",
    "                'exec_times_musec': exec_times_musec,\n",
    "                'det_annos': det_annos,\n",
    "                'annos_in_glob_coords': False,\n",
    "                'resolution': resolution_idx,\n",
    "                'result_str': result_str,\n",
    "        }\n",
    "\n",
    "        with open(f'sampled_dets_res{resolution_idx}.pkl', 'wb') as f:\n",
    "            pickle.dump(eval_d, f)\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ddfaa6-57c6-463c-bbaa-1bf8bea6f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "86631 sample,\n",
      "2654673 sample_data,\n",
      "2784931 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 26.971 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 7.2 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "from nuscenes import NuScenes\n",
    "\n",
    "dataset_version = 'v1.0-trainval'\n",
    "root_path = \"../data/nuscenes/\" + dataset_version\n",
    "loaded_nusc = NuScenes(version=dataset_version, dataroot=root_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2514a64d-d54d-4bfd-8f58-aba7f054efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:00:23,061   INFO  Loading NuScenes dataset\n",
      "2025-01-30 19:00:25,307   INFO  Total samples for NuScenes dataset: 58501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 58501 samples\n",
      "Default deadline is: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:00:25,901   INFO  ==> Loading parameters from checkpoint ../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth to GPU\n",
      "2025-01-30 19:00:26,026   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+31546c7+py52e9ef4\n",
      "2025-01-30 19:00:26,066   INFO  ==> Done (loaded 2106/2106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "***RESOLUTION INDEX 0**\n",
      "***********************\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "72.12\t74.36\t80.09\t114.91\t146.66\t155.11\t159.81\n",
      "Calibrating resolution 0\n",
      "Resolution idx: 0 Input: x_conv4 torch.Size([1, 256, 144, 144])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res0.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res0.engine successfully loaded.\n",
      "Optimization took 0.7383005619049072 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "55.12\t56.88\t62.96\t76.96\t91.30\t93.92\t104.57\n",
      "Calibrating resolution 1\n",
      "Resolution idx: 1 Input: x_conv4 torch.Size([1, 256, 96, 96])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res1.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res1.engine successfully loaded.\n",
      "Optimization took 0.04139852523803711 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "53.13\t53.49\t54.85\t63.97\t74.60\t75.79\t79.51\n",
      "Calibrating resolution 2\n",
      "Resolution idx: 2 Input: x_conv4 torch.Size([1, 256, 72, 72])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res2.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res2.engine successfully loaded.\n",
      "Optimization took 0.039272308349609375 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "48.71\t50.83\t51.81\t58.51\t63.08\t64.38\t71.86\n",
      "Calibrating resolution 3\n",
      "Resolution idx: 3 Input: x_conv4 torch.Size([1, 256, 60, 60])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res3.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res3.engine successfully loaded.\n",
      "Optimization took 0.03977394104003906 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "48.80\t49.11\t50.34\t54.84\t58.31\t61.89\t70.56\n",
      "Calibrating resolution 4\n",
      "Resolution idx: 4 Input: x_conv4 torch.Size([1, 256, 48, 48])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res4.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res4.engine successfully loaded.\n",
      "Optimization took 0.03956770896911621 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "|████████████████████████████████████████✗︎ (!) 100% [58503/58501] in 9:29.2 (102.79/s)                                                                          \n",
      " ,Min,Avrg,95perc,99perc,Max,Std_dev\n",
      "End-to-end,9.69,12.29,13.59,14.28,16.91,0.77\n",
      "PreProcess,0.30,0.46,0.52,0.79,2.80,0.05\n",
      "PostProcess,0.01,0.01,0.01,0.02,0.04,0.00\n",
      "Sched,0.24,0.29,0.35,0.49,1.26,0.03\n",
      "VFE,0.85,1.00,1.26,1.67,3.93,0.10\n",
      "Backbone3D,4.27,4.87,5.61,6.23,8.49,0.35\n",
      "DenseOps,2.46,4.40,5.05,5.41,7.51,0.51\n",
      "CenterHead-GenBox,0.68,1.14,1.55,1.82,4.16,0.21\n",
      "All numbers are in milliseconds\n",
      "Resolution selection stats:\n",
      "[0, 0, 0, 0, 0]\n",
      "Sampled 58501 objects\n",
      "STREAMING EVAL\n",
      "Do calibration flag is False\n",
      "Initializing nuScenes detection evaluation\n",
      "Loaded results. Found detections for 58501 samples.\n",
      "Loading annotations for val split from nuScenes version: v1.0-trainval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 58501/58501 [00:44<00:00, 1301.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ground truth annotations for 58501 samples.\n",
      "Filtering predictions\n",
      "=> Original number of boxes: 1928898\n",
      "=> After distance based filtering: 1563199\n",
      "=> After LIDAR points based filtering: 1563199\n",
      "=> After bike rack filtering: 1562142\n",
      "Filtering ground truth annotations\n",
      "=> Original number of boxes: 1768370\n",
      "=> After distance based filtering: 1282973\n",
      "=> After LIDAR points based filtering: 1158132\n",
      "=> After bike rack filtering: 1158031\n",
      "Accumulating metric data...\n",
      "Calculating metrics...\n",
      "Saving metrics to: tmp_results\n",
      "mAP: 0.4820\n",
      "mATE: 0.3779\n",
      "mASE: 0.2521\n",
      "mAOE: 0.3921\n",
      "mAVE: 0.2377\n",
      "mAAE: 0.1973\n",
      "NDS: 0.5953\n",
      "Eval time: 271.6s\n",
      "\n",
      "Per-class results:\n",
      "Object Class\tAP\tATE\tASE\tAOE\tAVE\tAAE\n",
      "car\t0.705\t0.280\t0.155\t0.133\t0.231\t0.192\n",
      "truck\t0.461\t0.412\t0.183\t0.139\t0.198\t0.210\n",
      "bus\t0.542\t0.441\t0.184\t0.108\t0.345\t0.266\n",
      "trailer\t0.287\t0.599\t0.220\t0.586\t0.214\t0.185\n",
      "construction_vehicle\t0.146\t0.700\t0.396\t1.045\t0.141\t0.348\n",
      "pedestrian\t0.729\t0.258\t0.274\t0.389\t0.213\t0.084\n",
      "motorcycle\t0.489\t0.340\t0.232\t0.394\t0.387\t0.276\n",
      "bicycle\t0.327\t0.233\t0.270\t0.628\t0.172\t0.017\n",
      "traffic_cone\t0.585\t0.213\t0.322\tnan\tnan\tnan\n",
      "barrier\t0.549\t0.304\t0.284\t0.106\tnan\tnan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:18:13,562   INFO  Loading NuScenes dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution index: 0\n",
      "Forecasting: True\n",
      "Resolution stats: [0, 0, 0, 0, 0]\n",
      "----------------Nuscene detection_cvpr_2019 results-----------------\n",
      "***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.28, 0.15, 0.13, 0.23, 0.19 | 51.96, 69.46, 78.63, 82.05 | mean AP: 0.7052372878813292\n",
      "***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.41, 0.18, 0.14, 0.20, 0.21 | 23.90, 44.31, 56.02, 60.23 | mean AP: 0.4611442260443158\n",
      "***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.70, 0.40, 1.05, 0.14, 0.35 | 1.00, 9.36, 20.05, 28.04 | mean AP: 0.14610865236814335\n",
      "***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.44, 0.18, 0.11, 0.34, 0.27 | 24.76, 49.38, 67.34, 75.25 | mean AP: 0.5418604694008866\n",
      "***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.60, 0.22, 0.59, 0.21, 0.19 | 4.02, 22.79, 37.97, 49.92 | mean AP: 0.28676059409203464\n",
      "***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.30, 0.28, 0.11, nan, nan | 38.36, 54.47, 62.05, 64.59 | mean AP: 0.5486394407893667\n",
      "***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.34, 0.23, 0.39, 0.39, 0.28 | 31.30, 48.64, 56.59, 59.21 | mean AP: 0.4893722220311867\n",
      "***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.23, 0.27, 0.63, 0.17, 0.02 | 27.69, 33.43, 34.61, 35.20 | mean AP: 0.32732737433651854\n",
      "***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.26, 0.27, 0.39, 0.21, 0.08 | 60.89, 71.47, 78.03, 81.12 | mean AP: 0.7287479303682023\n",
      "***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.21, 0.32, nan, nan, nan | 50.51, 57.12, 60.78, 65.56 | mean AP: 0.5849171246115422\n",
      "--------------average performance-------------\n",
      "trans_err:\t 0.3779\n",
      "scale_err:\t 0.2521\n",
      "orient_err:\t 0.3921\n",
      "vel_err:\t 0.2377\n",
      "attr_err:\t 0.1973\n",
      "mAP:\t 0.4820\n",
      "NDS:\t 0.5953\n",
      "\n",
      "Time passed (seconds): 1070.4978759288788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:18:15,546   INFO  Total samples for NuScenes dataset: 58501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 58501 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:18:16,115   INFO  ==> Loading parameters from checkpoint ../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth to GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default deadline is: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 19:18:16,244   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+31546c7+py52e9ef4\n",
      "2025-01-30 19:18:16,285   INFO  ==> Done (loaded 2106/2106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "***RESOLUTION INDEX 1**\n",
      "***********************\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "72.12\t74.36\t80.09\t114.91\t146.66\t155.11\t159.81\n",
      "Calibrating resolution 0\n",
      "Resolution idx: 0 Input: x_conv4 torch.Size([1, 256, 144, 144])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res0.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res0.engine successfully loaded.\n",
      "Optimization took 0.7148478031158447 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "55.12\t56.88\t62.96\t76.96\t91.30\t93.92\t104.57\n",
      "Calibrating resolution 1\n",
      "Resolution idx: 1 Input: x_conv4 torch.Size([1, 256, 96, 96])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res1.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res1.engine successfully loaded.\n",
      "Optimization took 0.04210615158081055 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "53.13\t53.49\t54.85\t63.97\t74.60\t75.79\t79.51\n",
      "Calibrating resolution 2\n",
      "Resolution idx: 2 Input: x_conv4 torch.Size([1, 256, 72, 72])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res2.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res2.engine successfully loaded.\n",
      "Optimization took 0.04091978073120117 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "48.71\t50.83\t51.81\t58.51\t63.08\t64.38\t71.86\n",
      "Calibrating resolution 3\n",
      "Resolution idx: 3 Input: x_conv4 torch.Size([1, 256, 60, 60])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res3.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res3.engine successfully loaded.\n",
      "Optimization took 0.040902137756347656 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "48.80\t49.11\t50.34\t54.84\t58.31\t61.89\t70.56\n",
      "Calibrating resolution 4\n",
      "Resolution idx: 4 Input: x_conv4 torch.Size([1, 256, 48, 48])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res4.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet_5res_valor_dense_convs_res4.engine successfully loaded.\n",
      "Optimization took 0.04054450988769531 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "|████████████████████████████████████████✗︎ (!) 100% [58502/58501] in 11:57.6 (81.52/s)                                                                          \n",
      " ,Min,Avrg,95perc,99perc,Max,Std_dev\n",
      "End-to-end,9.11,10.65,12.25,14.42,21.80,0.73\n",
      "PreProcess,0.30,0.48,0.63,1.83,6.33,0.09\n",
      "PostProcess,0.00,0.01,0.01,0.02,0.29,0.00\n",
      "Sched,0.25,0.32,0.48,0.62,4.78,0.06\n",
      "VFE,0.86,1.07,1.69,2.43,8.97,0.23\n",
      "Backbone3D,4.28,4.78,5.65,6.92,12.52,0.40\n",
      "DenseOps,1.96,2.74,3.10,3.24,7.10,0.23\n",
      "CenterHead-GenBox,0.67,1.11,1.52,1.88,7.16,0.20\n",
      "All numbers are in milliseconds\n",
      "Resolution selection stats:\n",
      "[0, 0, 0, 0, 0]\n",
      "Sampled 58501 objects\n",
      "STREAMING EVAL\n",
      "Do calibration flag is False\n",
      "Initializing nuScenes detection evaluation\n"
     ]
    }
   ],
   "source": [
    "import pcdet\n",
    "# import nuscenes.eval.detection.algo\n",
    "# import nuscenes.eval.detection.evaluate\n",
    "# importlib.reload(nuscenes.eval.detection.algo)\n",
    "# importlib.reload(nuscenes.eval.detection.evaluate)\n",
    "# importlib.reload(nuscenes.utils.data_classes)\n",
    "\n",
    "# Run single test\n",
    "# resolution_idx = 0\n",
    "# streaming = False\n",
    "# forecasting = False\n",
    "# model = build_model()\n",
    "# res_pred_mdl = res_pred_utils.ResolutionPredictor(model.num_res)\n",
    "# sampled_objects, exec_times_musec, resolution_stats = run_test(model, resolution_idx, loaded_nusc,\n",
    "                            # streaming=streaming, forecasting=forecasting, sched_period_ms=2000, collect_res_pred_data=True)\n",
    "# result_str = do_eval(sampled_objects, resolution_idx, model.dataset, exec_times_musec=exec_times_musec,\n",
    "#                              dump_eval_dict=False, loaded_nusc=loaded_nusc)\n",
    "# print(result_str)\n",
    "\n",
    "# Run batch test\n",
    "streaming = True\n",
    "offline = not streaming\n",
    "results = []\n",
    "num_res = 5\n",
    "skip_eval=False\n",
    "forecasting=True # ignored if offline\n",
    "for resolution_idx in range(num_res):\n",
    "    # os.environ[\"FINE_GRAINED_EVAL\"] = (\"1\" if resolution_idx >= 0 else \"0\")\n",
    "    t1 = time.time()\n",
    "    model = build_model()\n",
    "\n",
    "    sampled_objects, exec_times_musec, resolution_stats = run_test(model, resolution_idx, \n",
    "                                                                streaming=streaming, \n",
    "                                                                forecasting=forecasting, sched_period_ms=2000)\n",
    "    if not skip_eval:\n",
    "        # fname = f'tmp_results/detdata_res{resolution_idx}.pkl'\n",
    "        # with open(fname, 'rb') as f:\n",
    "        #     sampled_objects, exec_times_musec, resolution_stats = pickle.load(f)\n",
    "        #     print(f'Loaded {len(sampled_objects)} objects from {fname}')\n",
    "\n",
    "        dataset = model.dataset\n",
    "        del model\n",
    "        result_str = do_eval(sampled_objects, resolution_idx, dataset, exec_times_musec=exec_times_musec,\n",
    "                             dump_eval_dict=True, loaded_nusc=loaded_nusc)\n",
    "        results.append([resolution_idx, forecasting, resolution_stats, result_str])\n",
    "        result = results[-1]\n",
    "        print(f'Resolution index: {result[0]}')\n",
    "        print(f'Forecasting: {forecasting}')\n",
    "        print(f'Resolution stats: {result[2]}')\n",
    "        print(result[3])\n",
    "    t2 = time.time()\n",
    "    print('Time passed (seconds):', t2-t1)\n",
    "if not skip_eval:\n",
    "    with open(f\"output_streaming_{streaming}.txt\", \"w\") as f:\n",
    "        for resolution_idx, forecasting, resolution_stats, result_str in results:\n",
    "            if forecasting:\n",
    "                f.write('FORECASTING WAS UTILIZED\\n')\n",
    "            f.write(f'{resolution_stats}\\n')\n",
    "            f.write(result_str)\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
