{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e79a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/root/shared/Anytime-Lidar/tools\")\n",
    "os.environ[\"DATASET_PERIOD\"] = \"50\"\n",
    "os.environ[\"PMODE\"] = \"pmode_0002\" # same as jetson orin\n",
    "os.environ[\"STREVAL_TRAIN\"] = \"1\"\n",
    "\n",
    "import _init_path\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "from eval_utils import eval_utils\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import res_pred_utils\n",
    "import nuscenes\n",
    "import importlib\n",
    "# import numba\n",
    "import concurrent.futures\n",
    "\n",
    "def get_dataset(cfg):\n",
    "    log_file = './tmp_results/log_eval_%s' % datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    log_file = log_file + str(np.random.randint(0, 9999)) + '.txt'\n",
    "    logger = common_utils.create_logger(log_file, rank=0)\n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, batch_size=1,\n",
    "        dist=False, workers=0, logger=logger, training=False\n",
    "    )\n",
    "\n",
    "    return logger, test_set, test_loader, sampler\n",
    "\n",
    "def get_streaming_eval_samples(num_ds_elems : int, period_ms : int, output_times_ms : np.ndarray, pred_dicts_arr):\n",
    "    # Streaming eval\n",
    "    #Now do manual sampling base on time\n",
    "\n",
    "    #times_ns should be output_times_ms\n",
    "    sampled_objects = []\n",
    "    for i in range(num_ds_elems):\n",
    "        sample_time_ms = i*period_ms\n",
    "        aft = output_times_ms > sample_time_ms\n",
    "        if aft[0] == True:\n",
    "            sampled_objects.append(None) # Should be an empty pred dicts arr\n",
    "        elif aft[-1] == False:\n",
    "            sampled_objects.append(pred_dicts_arr[-1])\n",
    "        else:\n",
    "            sample_idx = np.argmax(aft) - 1\n",
    "            sampled_objects.append(pred_dicts_arr[sample_idx])\n",
    "\n",
    "    return sampled_objects\n",
    "\n",
    "def calc_tail_ms(cur_time_point_ms, data_period_ms):\n",
    "    return cur_time_point_ms - math.floor(cur_time_point_ms / data_period_ms) * data_period_ms\n",
    "\n",
    "def build_model():\n",
    "    cfg_file = \"./cfgs/nuscenes_models/pillar01_015_02_024_03_valor.yaml\"\n",
    "    cfg_from_yaml_file(cfg_file, cfg)\n",
    "    \n",
    "    set_cfgs = ['MODEL.METHOD', '0', 'MODEL.DEADLINE_SEC', '100.0', 'MODEL.DENSE_HEAD.NAME', 'CenterHeadInf',\n",
    "                'OPTIMIZATION.BATCH_SIZE_PER_GPU', '1']\n",
    "    cfg_from_list(set_cfgs, cfg)\n",
    "    logger, test_set, test_loader, sampler = get_dataset(cfg)\n",
    "    print(f'Loaded dataset with {len(test_set)} samples')\n",
    "    \n",
    "    ckpt_file=\"../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth\"\n",
    "    \n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "    model.load_params_from_file(filename=ckpt_file, logger=logger, to_cpu=False)\n",
    "    # model.pre_hook_handle.remove()\n",
    "    # model.post_hook_handle.remove()\n",
    "    model.eval() # should be run with @torch.no_grad\n",
    "    model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "@torch.jit.script\n",
    "def move_bounding_boxes(bboxes, egovel, time_diffs_sec):\n",
    "    outp_shape = (time_diffs_sec.shape[0], bboxes.shape[0], bboxes.shape[1])\n",
    "    outp_bboxes = torch.empty(outp_shape, dtype=bboxes.dtype)\n",
    "    outp_bboxes[:, :, 2:] = bboxes[:, 2:]\n",
    "\n",
    "    for t in range(time_diffs_sec.shape[0]):\n",
    "        outp_bboxes[t, :, :2] = bboxes[:, :2] + (bboxes[:, 7:9] - egovel) * time_diffs_sec[t]\n",
    "\n",
    "    return outp_bboxes\n",
    "\n",
    "def run_test(model, resolution_idx, loaded_nusc, streaming=True, forecasting=False, sched_period_ms=2000):\n",
    "    print('***********************')\n",
    "    print(f'***RESOLUTION INDEX {resolution_idx}**')\n",
    "    print('***********************')\n",
    "\n",
    "    data_period_ms = int(os.environ[\"DATASET_PERIOD\"])\n",
    "    num_samples = len(model.dataset)\n",
    "\n",
    "    cur_sample_idx = 0\n",
    "    sim_cur_time_ms = 0.\n",
    "    last_exec_time_ms = 100.\n",
    "    target_sched_time_ms = 0.\n",
    "    sampled_dets = [None] * num_samples\n",
    "    exec_times_ms = []\n",
    "    # sample_tokens = []\n",
    "    resolution_stats = [0] * model.num_res\n",
    "\n",
    "    model.calibrate()\n",
    "    do_res_sched = (resolution_idx == -1)\n",
    "    model.res_idx = 0 if do_res_sched else resolution_idx\n",
    "\n",
    "    with alive_bar(num_samples, force_tty=True, max_cols=160, manual=True) as bar:\n",
    "        while cur_sample_idx < num_samples:\n",
    "            with torch.no_grad():\n",
    "                lbd = model.latest_batch_dict # save bef its modified\n",
    "\n",
    "                pred_dicts, ret_dict = model([cur_sample_idx])\n",
    "\n",
    "            # Predict the execution time as if the DNN were to be executed on target platform\n",
    "            batch_dict = model.latest_batch_dict\n",
    "            num_points = batch_dict['points'].size(0)\n",
    "            num_voxels = np.array([batch_dict['bb3d_num_voxels']])\n",
    "            xlen = batch_dict['x_lims'][1] - batch_dict['x_lims'][0]\n",
    "            last_exec_time_ms = model.calibrators[model.res_idx].pred_exec_time_ms(\n",
    "               num_points, num_voxels, xlen)\n",
    "\n",
    "            sample_tkn = batch_dict['metadata'][0]['token']\n",
    "            if lbd is not None and not batch_dict['scene_reset']:\n",
    "                prev_sample_tkn = lbd['metadata'][0]['token']\n",
    "                egovel = res_pred_utils.get_2d_egovel(\n",
    "                        model.token_to_ts[prev_sample_tkn],\n",
    "                        model.token_to_pose[prev_sample_tkn],\n",
    "                        model.token_to_ts[sample_tkn],\n",
    "                        model.token_to_pose[sample_tkn])\n",
    "            else: # assume its zero\n",
    "                egovel = np.zeros(2)\n",
    "\n",
    "            if not streaming:\n",
    "                sim_cur_time_ms += data_period_ms\n",
    "                sampled_dets[cur_sample_idx] = pred_dicts\n",
    "                exec_times_ms.append(last_exec_time_ms)\n",
    "            else:\n",
    "                # the sampled_dets can be overwritten, which is okay\n",
    "                sim_cur_time_ms += last_exec_time_ms\n",
    "                num_to_forecast = 500 // data_period_ms\n",
    "                future_sample_inds = [(sim_cur_time_ms+(i*data_period_ms))//data_period_ms for i in range(1,num_to_forecast+1)]\n",
    "                future_sample_inds = torch.tensor([ind for ind in future_sample_inds if ind < num_samples]).int()\n",
    "                if forecasting: # NOTE consider the overhead here\n",
    "                    # Forecast for next 500 ms\n",
    "                    time_diffs_sec = (future_sample_inds * data_period_ms - (sim_cur_time_ms - last_exec_time_ms)) * 1e-3\n",
    "                    outp_bboxes_all = move_bounding_boxes(pred_dicts[0]['pred_boxes'], torch.from_numpy(egovel), time_diffs_sec)\n",
    "                    for outp_bboxes, sample_ind_f in zip(outp_bboxes_all, future_sample_inds.tolist()):\n",
    "                        forecasted_pd = {k : pred_dicts[0][k] for k in ('pred_scores', 'pred_labels')}\n",
    "                        forecasted_pd['pred_boxes'] = outp_bboxes\n",
    "                        sampled_dets[sample_ind_f] = [forecasted_pd]\n",
    "                else:\n",
    "                    for sample_ind_f in future_sample_inds.tolist():\n",
    "                        sampled_dets[sample_ind_f] = pred_dicts\n",
    "\n",
    "            if do_res_sched and sim_cur_time_ms >= target_sched_time_ms:\n",
    "                #NOTE Time prediction does not work all the time, \n",
    "                # res_exec_times_sec = []\n",
    "                # for ridx in range(model.num_res):\n",
    "                #     if ridx == model.res_idx:\n",
    "                #         res_exec_times_sec.append(last_exec_time_ms)\n",
    "                #     else:\n",
    "                #         # WARNING!!!!! num voxels and xlen change depending on resolution!\n",
    "                #         res_exec_times_sec.append(model.calibrators[ridx].pred_exec_time_ms(\n",
    "                #                 num_points, num_voxels, xlen))\n",
    "                # print('resolution exec times (seconds):')\n",
    "                # print(res_exec_times_sec)\n",
    "                res_exec_times_sec = np.array([0.247, 0.147, 0.107, 0.091, 0.077]) # mean\n",
    "                ratio = (last_exec_time_ms/1000.) / res_exec_times_sec[model.res_idx]\n",
    "                chosen_res = res_pred_utils.pick_best_resolution(res_exec_times_sec * ratio,\n",
    "                                                                 egovel, pred_dicts[0])\n",
    "                model.res_idx = chosen_res\n",
    "                #NOTE I need to consider the sched time as well and add to sim cur time ms\n",
    "                target_sched_time_ms += sched_period_ms\n",
    "                \n",
    "            resolution_stats[model.res_idx] += 1\n",
    "\n",
    "            #Dynamic scheduling\n",
    "            if streaming:\n",
    "                cur_tail = calc_tail_ms(sim_cur_time_ms, data_period_ms)\n",
    "                pred_finish_time = sim_cur_time_ms + last_exec_time_ms #NOTE I can also use mean exec time\n",
    "                next_tail = calc_tail_ms(pred_finish_time, data_period_ms)\n",
    "                if next_tail < cur_tail:\n",
    "                    # Sleep, extra 1 ms is added to make sure sleep time is enough\n",
    "                    sim_cur_time_ms += data_period_ms - cur_tail + 1\n",
    "\n",
    "                next_sample_idx = int(sim_cur_time_ms / data_period_ms)\n",
    "            else:\n",
    "                next_sample_idx = cur_sample_idx + 1\n",
    "                \n",
    "            if cur_sample_idx == next_sample_idx:\n",
    "                print(f'ERROR, trying to process already processed sample {next_sample_idx}')\n",
    "            \n",
    "            cur_sample_idx = next_sample_idx\n",
    "            bar(cur_sample_idx / num_samples)\n",
    "\n",
    "    if do_res_sched:\n",
    "        model.res_idx = -1\n",
    "    model.print_time_stats()\n",
    "    print('Resolution selection stats:')\n",
    "    print(resolution_stats)\n",
    "\n",
    "    # exec_times_ms = np.full((len(exec_times_ms),), 1.)\n",
    "    if streaming:\n",
    "        # sampled_dets = get_streaming_eval_samples(num_samples, data_period_ms, output_times_ms, all_pred_dicts)\n",
    "        exec_times_musec = None\n",
    "    else:\n",
    "        sample_tokens = [model.dataset.infos[i]['token'] for i in range(num_samples)]\n",
    "        exec_times_ms = np.array(exec_times_ms)\n",
    "        exec_times_musec = exec_times_ms * 1000\n",
    "        exec_times_musec = {st:outp_t for st,outp_t in zip(sample_tokens, exec_times_musec)}\n",
    "\n",
    "    with open(f'tmp_results/detdata_res{model.res_idx}.pkl', 'wb') as f:\n",
    "        pickle.dump([sampled_dets, exec_times_musec, resolution_stats], f)\n",
    "\n",
    "    print(f'Sampled {len(sampled_dets)} objects')\n",
    "    return sampled_dets, exec_times_musec, resolution_stats\n",
    "\n",
    "def do_eval(sampled_objects, resolution_idx, dataset, exec_times_musec=None, dump_eval_dict=True, loaded_nusc=None):\n",
    "    #Convert them to openpcdet format\n",
    "    os.environ[\"RESOLUTION_IDX\"] = str(model.res_idx)\n",
    "    \n",
    "    det_annos = []\n",
    "    num_ds_elems = len(dataset)\n",
    "    for i in range(num_ds_elems):\n",
    "        data_dict = dataset.get_metadata_dict(i)\n",
    "        for k, v in data_dict.items():\n",
    "            data_dict[k] = [v] # make it a batch dict\n",
    "        # print(i)\n",
    "        pred_dicts = sampled_objects[i]\n",
    "\n",
    "        if pred_dicts is None:\n",
    "            pred_dicts = [{\n",
    "                'pred_boxes': torch.empty((0, 9)),\n",
    "                'pred_scores': torch.empty(0),\n",
    "                'pred_labels': torch.empty(0, dtype=torch.long)\n",
    "            }]\n",
    "        data_dict['final_box_dicts'] = pred_dicts\n",
    "        det_annos += dataset.generate_prediction_dicts(\n",
    "            data_dict, data_dict['final_box_dicts'], dataset.class_names, output_path=None\n",
    "        )\n",
    "\n",
    "    #nusc_annos = {} # not needed but keep it anyway\n",
    "    result_str, result_dict = dataset.evaluation(\n",
    "        det_annos, dataset.class_names,\n",
    "        eval_metric='kitti', #model.model_cfg.POST_PROCESSING.EVAL_METRIC,\n",
    "        output_path='./tmp_results',\n",
    "        boxes_in_global_coords=False,\n",
    "        loaded_nusc=loaded_nusc,\n",
    "        det_elapsed_musec=exec_times_musec\n",
    "    )\n",
    "\n",
    "    if dump_eval_dict:\n",
    "        eval_d = {\n",
    "        'cfg': cfg,\n",
    "        'det_annos': det_annos,\n",
    "        'annos_in_glob_coords': False,\n",
    "        'resolution': resolution_idx\n",
    "        }\n",
    "    \n",
    "        eval_d['result_str'] = result_str\n",
    "    \n",
    "        with open(f'sampled_dets_res{resolution_idx}.pkl', 'wb') as f:\n",
    "            pickle.dump(eval_d, f)\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddfaa6-57c6-463c-bbaa-1bf8bea6f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "\n",
    "dataset_version = 'v1.0-trainval'\n",
    "root_path = \"../data/nuscenes/\" + dataset_version\n",
    "loaded_nusc = NuScenes(version=dataset_version, dataroot=root_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2514a64d-d54d-4bfd-8f58-aba7f054efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:26:06,687   INFO  Loading NuScenes dataset\n",
      "2024-11-05 14:26:07,114   INFO  Total samples for NuScenes dataset: 11709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 11709 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:26:09,623   INFO  ==> Loading parameters from checkpoint ../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth to GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default deadline is: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:26:09,745   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+31546c7+py52e9ef4\n",
      "2024-11-05 14:26:09,781   INFO  ==> Done (loaded 2106/2106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "***RESOLUTION INDEX 0**\n",
      "***********************\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "127.59\t135.05\t160.44\t247.69\t330.08\t353.76\t366.01\n",
      "Calibrating resolution 0\n",
      "Resolution idx: 0 Input: x_conv4 torch.Size([1, 256, 144, 144])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res0.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res0.engine successfully loaded.\n",
      "Optimization took 0.7048311233520508 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "82.61\t88.78\t103.24\t147.58\t189.00\t198.18\t205.38\n",
      "Calibrating resolution 1\n",
      "Resolution idx: 1 Input: x_conv4 torch.Size([1, 256, 96, 96])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res1.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res1.engine successfully loaded.\n",
      "Optimization took 0.04704022407531738 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "72.49\t73.65\t79.19\t107.98\t139.25\t142.09\t146.19\n",
      "Calibrating resolution 2\n",
      "Resolution idx: 2 Input: x_conv4 torch.Size([1, 256, 72, 72])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res2.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res2.engine successfully loaded.\n",
      "Optimization took 0.044651031494140625 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "60.35\t66.29\t70.47\t91.03\t109.09\t111.85\t115.95\n",
      "Calibrating resolution 3\n",
      "Resolution idx: 3 Input: x_conv4 torch.Size([1, 256, 60, 60])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res3.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res3.engine successfully loaded.\n",
      "Optimization took 0.04538297653198242 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "58.33\t59.13\t64.73\t77.46\t88.68\t91.06\t92.69\n",
      "Calibrating resolution 4\n",
      "Resolution idx: 4 Input: x_conv4 torch.Size([1, 256, 48, 48])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res4.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res4.engine successfully loaded.\n",
      "Optimization took 0.045349836349487305 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "|████████████████████████████████████████| 100% [11709/11709] in 51.4s (227.91/s)                                                                               \n",
      " ,Min,Avrg,95perc,99perc,Max,Std_dev\n",
      "End-to-end,9.65,11.86,12.85,13.15,13.75,0.66\n",
      "PreProcess,0.30,0.38,0.41,0.45,0.79,0.02\n",
      "PostProcess,0.01,0.01,0.01,0.02,0.03,0.00\n",
      "Sched,0.28,0.29,0.30,0.32,0.80,0.01\n",
      "VFE,0.87,0.97,1.06,1.39,1.92,0.06\n",
      "Backbone3D,4.27,4.68,5.24,5.46,5.89,0.26\n",
      "DenseOps,2.77,4.35,4.79,4.81,4.89,0.50\n",
      "CenterHead-GenBox,0.74,1.08,1.46,1.58,1.79,0.18\n",
      "All numbers are in milliseconds\n",
      "Resolution selection stats:\n",
      "[2061, 0, 0, 0, 0]\n",
      "Sampled 11709 objects\n",
      "Loaded 11709 objects from file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:27:34,254   INFO  The predictions of NuScenes have been saved to tmp_results/results_nusc.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do calibration flag is False\n",
      "Initializing nuScenes detection evaluation\n",
      "Loaded results from tmp_results/results_nusc.json. Found detections for 11709 samples.\n",
      "Loading annotations for val split from nuScenes version: v1.0-trainval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 11709/11709 [00:07<00:00, 1499.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ground truth annotations for 11709 samples.\n",
      "Filtering predictions\n",
      "=> Original number of boxes: 378581\n",
      "=> After distance based filtering: 315064\n",
      "=> After LIDAR points based filtering: 315064\n",
      "=> After bike rack filtering: 315064\n",
      "Filtering ground truth annotations\n",
      "=> Original number of boxes: 332140\n",
      "=> After distance based filtering: 250595\n",
      "=> After LIDAR points based filtering: 229014\n",
      "=> After bike rack filtering: 229014\n",
      "Doing fine grained eval\n",
      "Accumulating metric data...\n",
      "Calculating metrics...\n",
      "Saving metrics to: tmp_results\n",
      "mAP: 0.1348\n",
      "mATE: 0.7751\n",
      "mASE: 0.2528\n",
      "mAOE: 0.7070\n",
      "mAVE: 0.2254\n",
      "mAAE: 0.1398\n",
      "NDS: 0.3574\n",
      "Eval time: 55.5s\n",
      "\n",
      "Per-class results:\n",
      "Object Class\tAP\tATE\tASE\tAOE\tAVE\tAAE\n",
      "car\t0.192\t0.762\t0.168\t0.192\t0.273\t0.250\n",
      "truck\t0.071\t0.583\t0.217\t0.258\t0.129\t0.211\n",
      "bus\t0.281\t0.871\t0.165\t0.044\t0.432\t0.151\n",
      "trailer\t0.030\t1.182\t0.204\t1.870\t0.187\t0.007\n",
      "construction_vehicle\t0.058\t0.205\t0.280\t2.307\t0.036\t0.003\n",
      "pedestrian\t0.186\t0.912\t0.278\t0.520\t0.337\t0.103\n",
      "motorcycle\t0.058\t1.087\t0.299\t0.755\t0.135\t0.286\n",
      "bicycle\t0.063\t0.730\t0.300\t0.272\t0.273\t0.107\n",
      "traffic_cone\t0.295\t0.433\t0.321\tnan\tnan\tnan\n",
      "barrier\t0.114\t0.987\t0.295\t0.144\tnan\tnan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:28:51,608   INFO  Loading NuScenes dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution index: 0\n",
      "Forecasting: False\n",
      "Resolution stats: [2061, 0, 0, 0, 0]\n",
      "----------------Nuscene detection_cvpr_2019 results-----------------\n",
      "***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.76, 0.17, 0.19, 0.27, 0.25 | 1.16, 4.69, 15.63, 55.42 | mean AP: 0.19226681675419355\n",
      "***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.58, 0.22, 0.26, 0.13, 0.21 | 0.25, 1.21, 3.12, 23.80 | mean AP: 0.07094808460919477\n",
      "***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.20, 0.28, 2.31, 0.04, 0.00 | 3.38, 3.69, 4.39, 11.79 | mean AP: 0.05812342133780076\n",
      "***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.87, 0.17, 0.04, 0.43, 0.15 | 1.81, 9.16, 32.82, 68.80 | mean AP: 0.2814700341456707\n",
      "***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "1.18, 0.20, 1.87, 0.19, 0.01 | 0.00, 0.00, 0.54, 11.45 | mean AP: 0.029956670930970555\n",
      "***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.99, 0.29, 0.14, nan, nan | 0.00, 2.66, 13.56, 29.56 | mean AP: 0.11445154228724189\n",
      "***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "1.09, 0.30, 0.75, 0.14, 0.29 | 0.00, 0.00, 1.65, 21.43 | mean AP: 0.057704830527049625\n",
      "***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.73, 0.30, 0.27, 0.27, 0.11 | 0.00, 2.39, 7.85, 14.77 | mean AP: 0.06253627574495935\n",
      "***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.91, 0.28, 0.52, 0.34, 0.10 | 0.33, 4.14, 16.58, 53.39 | mean AP: 0.18608933997435456\n",
      "***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.43, 0.32, nan, nan, nan | 13.14, 19.40, 30.22, 55.13 | mean AP: 0.2947174541936988\n",
      "--------------average performance-------------\n",
      "trans_err:\t 0.7751\n",
      "scale_err:\t 0.2528\n",
      "orient_err:\t 0.7070\n",
      "vel_err:\t 0.2254\n",
      "attr_err:\t 0.1398\n",
      "mAP:\t 0.1348\n",
      "NDS:\t 0.3574\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:28:52,028   INFO  Total samples for NuScenes dataset: 11709\n",
      "2024-11-05 14:28:52,181   INFO  ==> Loading parameters from checkpoint ../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth to GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 11709 samples\n",
      "Default deadline is: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:28:52,302   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+31546c7+py52e9ef4\n",
      "2024-11-05 14:28:52,338   INFO  ==> Done (loaded 2106/2106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "***RESOLUTION INDEX 1**\n",
      "***********************\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "127.59\t135.05\t160.44\t247.69\t330.08\t353.76\t366.01\n",
      "Calibrating resolution 0\n",
      "Resolution idx: 0 Input: x_conv4 torch.Size([1, 256, 144, 144])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res0.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res0.engine successfully loaded.\n",
      "Optimization took 0.703016996383667 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "82.61\t88.78\t103.24\t147.58\t189.00\t198.18\t205.38\n",
      "Calibrating resolution 1\n",
      "Resolution idx: 1 Input: x_conv4 torch.Size([1, 256, 96, 96])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res1.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res1.engine successfully loaded.\n",
      "Optimization took 0.04602479934692383 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "72.49\t73.65\t79.19\t107.98\t139.25\t142.09\t146.19\n",
      "Calibrating resolution 2\n",
      "Resolution idx: 2 Input: x_conv4 torch.Size([1, 256, 72, 72])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res2.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res2.engine successfully loaded.\n",
      "Optimization took 0.04474949836730957 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "60.35\t66.29\t70.47\t91.03\t109.09\t111.85\t115.95\n",
      "Calibrating resolution 3\n",
      "Resolution idx: 3 Input: x_conv4 torch.Size([1, 256, 60, 60])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res3.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res3.engine successfully loaded.\n",
      "Optimization took 0.04376101493835449 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "58.33\t59.13\t64.73\t77.46\t88.68\t91.06\t92.69\n",
      "Calibrating resolution 4\n",
      "Resolution idx: 4 Input: x_conv4 torch.Size([1, 256, 48, 48])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res4.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res4.engine successfully loaded.\n",
      "Optimization took 0.044638633728027344 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "|████████████████████████████████████████✗︎ (!) 100% [11712/11709] in 1:20.0 (146.40/s)                                                                          \n",
      " ,Min,Avrg,95perc,99perc,Max,Std_dev\n",
      "End-to-end,9.01,9.92,10.54,10.86,13.69,0.34\n",
      "PreProcess,0.31,0.38,0.41,0.46,0.84,0.02\n",
      "PostProcess,0.01,0.01,0.01,0.02,0.08,0.00\n",
      "Sched,0.28,0.29,0.30,0.32,0.77,0.01\n",
      "VFE,0.88,0.99,1.10,1.44,1.83,0.07\n",
      "Backbone3D,4.16,4.37,4.87,5.05,7.18,0.16\n",
      "DenseOps,2.16,2.73,2.91,2.92,2.97,0.22\n",
      "CenterHead-GenBox,0.70,1.04,1.37,1.48,1.64,0.16\n",
      "All numbers are in milliseconds\n",
      "Resolution selection stats:\n",
      "[0, 3504, 0, 0, 0]\n",
      "Sampled 11709 objects\n",
      "Loaded 11709 objects from file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:30:49,264   INFO  The predictions of NuScenes have been saved to tmp_results/results_nusc.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do calibration flag is False\n",
      "Initializing nuScenes detection evaluation\n",
      "Loaded results from tmp_results/results_nusc.json. Found detections for 11709 samples.\n",
      "Loading annotations for val split from nuScenes version: v1.0-trainval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 11709/11709 [00:07<00:00, 1541.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ground truth annotations for 11709 samples.\n",
      "Filtering predictions\n",
      "=> Original number of boxes: 398178\n",
      "=> After distance based filtering: 325384\n",
      "=> After LIDAR points based filtering: 325384\n",
      "=> After bike rack filtering: 325343\n",
      "Filtering ground truth annotations\n",
      "=> Original number of boxes: 332140\n",
      "=> After distance based filtering: 250595\n",
      "=> After LIDAR points based filtering: 229014\n",
      "=> After bike rack filtering: 229014\n",
      "Doing fine grained eval\n",
      "Accumulating metric data...\n",
      "Calculating metrics...\n",
      "Saving metrics to: tmp_results\n",
      "mAP: 0.2188\n",
      "mATE: 0.8804\n",
      "mASE: 0.2597\n",
      "mAOE: 0.5004\n",
      "mAVE: 0.2058\n",
      "mAAE: 0.1098\n",
      "NDS: 0.4138\n",
      "Eval time: 67.6s\n",
      "\n",
      "Per-class results:\n",
      "Object Class\tAP\tATE\tASE\tAOE\tAVE\tAAE\n",
      "car\t0.308\t0.870\t0.160\t0.168\t0.227\t0.223\n",
      "truck\t0.175\t0.949\t0.203\t0.311\t0.149\t0.200\n",
      "bus\t0.422\t0.753\t0.171\t0.036\t0.357\t0.151\n",
      "trailer\t0.088\t1.221\t0.212\t1.553\t0.161\t0.000\n",
      "construction_vehicle\t0.116\t0.535\t0.393\t0.838\t0.059\t0.027\n",
      "pedestrian\t0.328\t0.900\t0.279\t0.433\t0.283\t0.091\n",
      "motorcycle\t0.124\t1.122\t0.284\t0.781\t0.179\t0.140\n",
      "bicycle\t0.092\t0.735\t0.273\t0.256\t0.231\t0.046\n",
      "traffic_cone\t0.366\t0.626\t0.322\tnan\tnan\tnan\n",
      "barrier\t0.170\t1.092\t0.300\t0.127\tnan\tnan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:32:19,354   INFO  Loading NuScenes dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution index: 1\n",
      "Forecasting: False\n",
      "Resolution stats: [0, 3504, 0, 0, 0]\n",
      "----------------Nuscene detection_cvpr_2019 results-----------------\n",
      "***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.87, 0.16, 0.17, 0.23, 0.22 | 2.27, 8.29, 36.06, 76.72 | mean AP: 0.30833020826531665\n",
      "***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.95, 0.20, 0.31, 0.15, 0.20 | 0.69, 2.12, 14.09, 52.91 | mean AP: 0.1745349694626106\n",
      "***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.54, 0.39, 0.84, 0.06, 0.03 | 3.94, 5.20, 10.15, 27.11 | mean AP: 0.11599054048423077\n",
      "***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.75, 0.17, 0.04, 0.36, 0.15 | 6.24, 22.82, 64.45, 75.09 | mean AP: 0.4215196906811066\n",
      "***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "1.22, 0.21, 1.55, 0.16, 0.00 | 0.00, 0.00, 9.93, 25.17 | mean AP: 0.08775978134658258\n",
      "***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "1.09, 0.30, 0.13, nan, nan | 0.00, 3.50, 26.30, 38.26 | mean AP: 0.17014842811241515\n",
      "***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "1.12, 0.28, 0.78, 0.18, 0.14 | 0.00, 0.35, 12.95, 36.26 | mean AP: 0.12389434139343682\n",
      "***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.73, 0.27, 0.26, 0.23, 0.05 | 0.02, 5.63, 12.09, 19.10 | mean AP: 0.09210606953128236\n",
      "***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.90, 0.28, 0.43, 0.28, 0.09 | 2.00, 11.88, 43.15, 74.27 | mean AP: 0.3282369979052175\n",
      "***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.63, 0.32, nan, nan, nan | 11.26, 21.02, 47.78, 66.26 | mean AP: 0.36577667505963457\n",
      "--------------average performance-------------\n",
      "trans_err:\t 0.8804\n",
      "scale_err:\t 0.2597\n",
      "orient_err:\t 0.5004\n",
      "vel_err:\t 0.2058\n",
      "attr_err:\t 0.1098\n",
      "mAP:\t 0.2188\n",
      "NDS:\t 0.4138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:32:19,786   INFO  Total samples for NuScenes dataset: 11709\n",
      "2024-11-05 14:32:19,936   INFO  ==> Loading parameters from checkpoint ../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth to GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 11709 samples\n",
      "Default deadline is: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:32:20,058   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+31546c7+py52e9ef4\n",
      "2024-11-05 14:32:20,093   INFO  ==> Done (loaded 2106/2106)\n",
      "/root/shared/Anytime-Lidar/tools/../pcdet/models/detectors/valor_calibrator.py:159: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(1, 1, figsize=(6, 4), constrained_layout=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "***RESOLUTION INDEX 2**\n",
      "***********************\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "127.59\t135.05\t160.44\t247.69\t330.08\t353.76\t366.01\n",
      "Calibrating resolution 0\n",
      "Resolution idx: 0 Input: x_conv4 torch.Size([1, 256, 144, 144])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res0.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res0.engine successfully loaded.\n",
      "Optimization took 0.7037551403045654 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "82.61\t88.78\t103.24\t147.58\t189.00\t198.18\t205.38\n",
      "Calibrating resolution 1\n",
      "Resolution idx: 1 Input: x_conv4 torch.Size([1, 256, 96, 96])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res1.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res1.engine successfully loaded.\n",
      "Optimization took 0.04598283767700195 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "72.49\t73.65\t79.19\t107.98\t139.25\t142.09\t146.19\n",
      "Calibrating resolution 2\n",
      "Resolution idx: 2 Input: x_conv4 torch.Size([1, 256, 72, 72])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res2.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res2.engine successfully loaded.\n",
      "Optimization took 0.045278310775756836 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "60.35\t66.29\t70.47\t91.03\t109.09\t111.85\t115.95\n",
      "Calibrating resolution 3\n",
      "Resolution idx: 3 Input: x_conv4 torch.Size([1, 256, 60, 60])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res3.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res3.engine successfully loaded.\n",
      "Optimization took 0.04520773887634277 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "58.33\t59.13\t64.73\t77.46\t88.68\t91.06\t92.69\n",
      "Calibrating resolution 4\n",
      "Resolution idx: 4 Input: x_conv4 torch.Size([1, 256, 48, 48])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res4.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res4.engine successfully loaded.\n",
      "Optimization took 0.044783830642700195 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "|████████████████████████████████████████| 100% [11709/11709] in 1:44.3 (112.30/s)                                                                              \n",
      " ,Min,Avrg,95perc,99perc,Max,Std_dev\n",
      "End-to-end,8.49,9.18,9.72,10.02,12.64,0.26\n",
      "PreProcess,0.30,0.38,0.40,0.46,1.10,0.02\n",
      "PostProcess,0.01,0.01,0.01,0.02,0.28,0.00\n",
      "Sched,0.28,0.29,0.30,0.33,0.90,0.01\n",
      "VFE,0.89,1.00,1.11,1.50,1.77,0.07\n",
      "Backbone3D,4.10,4.31,4.83,5.03,7.14,0.17\n",
      "DenseOps,1.77,2.06,2.13,2.15,2.34,0.10\n",
      "CenterHead-GenBox,0.71,1.02,1.29,1.40,1.59,0.14\n",
      "All numbers are in milliseconds\n",
      "Resolution selection stats:\n",
      "[0, 0, 4670, 0, 0]\n",
      "Sampled 11709 objects\n",
      "Loaded 11709 objects from file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:34:41,177   INFO  The predictions of NuScenes have been saved to tmp_results/results_nusc.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do calibration flag is False\n",
      "Initializing nuScenes detection evaluation\n",
      "Loaded results from tmp_results/results_nusc.json. Found detections for 11709 samples.\n",
      "Loading annotations for val split from nuScenes version: v1.0-trainval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 11709/11709 [00:07<00:00, 1507.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ground truth annotations for 11709 samples.\n",
      "Filtering predictions\n",
      "=> Original number of boxes: 416001\n",
      "=> After distance based filtering: 338466\n",
      "=> After LIDAR points based filtering: 338466\n",
      "=> After bike rack filtering: 338414\n",
      "Filtering ground truth annotations\n",
      "=> Original number of boxes: 332140\n",
      "=> After distance based filtering: 250595\n",
      "=> After LIDAR points based filtering: 229014\n",
      "=> After bike rack filtering: 229014\n",
      "Doing fine grained eval\n",
      "Accumulating metric data...\n",
      "Calculating metrics...\n",
      "Saving metrics to: tmp_results\n",
      "mAP: 0.2665\n",
      "mATE: 0.8356\n",
      "mASE: 0.2543\n",
      "mAOE: 0.4576\n",
      "mAVE: 0.2288\n",
      "mAAE: 0.1118\n",
      "NDS: 0.4445\n",
      "Eval time: 74.0s\n",
      "\n",
      "Per-class results:\n",
      "Object Class\tAP\tATE\tASE\tAOE\tAVE\tAAE\n",
      "car\t0.392\t0.867\t0.158\t0.170\t0.221\t0.231\n",
      "truck\t0.231\t0.990\t0.204\t0.176\t0.152\t0.167\n",
      "bus\t0.517\t0.585\t0.172\t0.031\t0.413\t0.174\n",
      "trailer\t0.119\t1.078\t0.205\t1.436\t0.170\t0.001\n",
      "construction_vehicle\t0.121\t0.678\t0.373\t0.707\t0.121\t0.106\n",
      "pedestrian\t0.377\t0.844\t0.282\t0.391\t0.279\t0.088\n",
      "motorcycle\t0.158\t1.057\t0.259\t0.742\t0.236\t0.110\n",
      "bicycle\t0.111\t0.613\t0.263\t0.353\t0.238\t0.017\n",
      "traffic_cone\t0.411\t0.609\t0.328\tnan\tnan\tnan\n",
      "barrier\t0.229\t1.036\t0.299\t0.113\tnan\tnan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:36:18,715   INFO  Loading NuScenes dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution index: 2\n",
      "Forecasting: False\n",
      "Resolution stats: [0, 0, 4670, 0, 0]\n",
      "----------------Nuscene detection_cvpr_2019 results-----------------\n",
      "***car error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.87, 0.16, 0.17, 0.22, 0.23 | 3.36, 14.10, 58.04, 81.39 | mean AP: 0.3922457491746402\n",
      "***truck error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.99, 0.20, 0.18, 0.15, 0.17 | 0.70, 3.21, 31.28, 57.23 | mean AP: 0.2310396581689748\n",
      "***construction_vehicle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.68, 0.37, 0.71, 0.12, 0.11 | 2.35, 4.27, 13.76, 27.91 | mean AP: 0.12070965638753801\n",
      "***bus error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.58, 0.17, 0.03, 0.41, 0.17 | 12.89, 40.04, 72.63, 81.24 | mean AP: 0.5170096962599047\n",
      "***trailer error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "1.08, 0.20, 1.44, 0.17, 0.00 | 0.00, 1.47, 18.30, 27.69 | mean AP: 0.11862631193876405\n",
      "***barrier error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "1.04, 0.30, 0.11, nan, nan | 0.00, 6.84, 38.65, 46.03 | mean AP: 0.2287953095064955\n",
      "***motorcycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "1.06, 0.26, 0.74, 0.24, 0.11 | 0.00, 2.41, 24.08, 36.68 | mean AP: 0.15792912049260768\n",
      "***bicycle error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.61, 0.26, 0.35, 0.24, 0.02 | 1.43, 8.73, 14.79, 19.55 | mean AP: 0.11126297303425214\n",
      "***pedestrian error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.84, 0.28, 0.39, 0.28, 0.09 | 2.95, 17.96, 57.59, 72.26 | mean AP: 0.376893176540473\n",
      "***traffic_cone error@trans, scale, orient, vel, attr | AP@0.5, 1.0, 2.0, 4.0\n",
      "0.61, 0.33, nan, nan, nan | 11.65, 28.18, 56.74, 67.74 | mean AP: 0.41080104404124124\n",
      "--------------average performance-------------\n",
      "trans_err:\t 0.8356\n",
      "scale_err:\t 0.2543\n",
      "orient_err:\t 0.4576\n",
      "vel_err:\t 0.2288\n",
      "attr_err:\t 0.1118\n",
      "mAP:\t 0.2665\n",
      "NDS:\t 0.4445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:36:19,144   INFO  Total samples for NuScenes dataset: 11709\n",
      "2024-11-05 14:36:19,295   INFO  ==> Loading parameters from checkpoint ../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth to GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 11709 samples\n",
      "Default deadline is: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:36:19,417   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+31546c7+py52e9ef4\n",
      "2024-11-05 14:36:19,453   INFO  ==> Done (loaded 2106/2106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "***RESOLUTION INDEX 3**\n",
      "***********************\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "127.59\t135.05\t160.44\t247.69\t330.08\t353.76\t366.01\n",
      "Calibrating resolution 0\n",
      "Resolution idx: 0 Input: x_conv4 torch.Size([1, 256, 144, 144])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res0.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res0.engine successfully loaded.\n",
      "Optimization took 0.6967880725860596 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "82.61\t88.78\t103.24\t147.58\t189.00\t198.18\t205.38\n",
      "Calibrating resolution 1\n",
      "Resolution idx: 1 Input: x_conv4 torch.Size([1, 256, 96, 96])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res1.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res1.engine successfully loaded.\n",
      "Optimization took 0.04574465751647949 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "72.49\t73.65\t79.19\t107.98\t139.25\t142.09\t146.19\n",
      "Calibrating resolution 2\n",
      "Resolution idx: 2 Input: x_conv4 torch.Size([1, 256, 72, 72])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res2.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res2.engine successfully loaded.\n",
      "Optimization took 0.04512333869934082 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "60.35\t66.29\t70.47\t91.03\t109.09\t111.85\t115.95\n",
      "Calibrating resolution 3\n",
      "Resolution idx: 3 Input: x_conv4 torch.Size([1, 256, 60, 60])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res3.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res3.engine successfully loaded.\n",
      "Optimization took 0.044586896896362305 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "58.33\t59.13\t64.73\t77.46\t88.68\t91.06\t92.69\n",
      "Calibrating resolution 4\n",
      "Resolution idx: 4 Input: x_conv4 torch.Size([1, 256, 48, 48])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res4.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0002/pillarnet01_valo_dense_convs_res4.engine successfully loaded.\n",
      "Optimization took 0.044523000717163086 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "|███████████████████████████████████▊    | ▆█▆ 89% [10470/11709] in 1:51 (~13s, 94.5/s)                                                                         "
     ]
    }
   ],
   "source": [
    "# importlib.reload(res_pred_utils)\n",
    "# importlib.reload(nuscenes.eval.detection.evaluate)\n",
    "# importlib.reload(nuscenes.utils.data_classes)\n",
    "\n",
    "# Run test\n",
    "# resolution_idx = -1\n",
    "# streaming = True\n",
    "# forecasting = True\n",
    "\n",
    "os.environ[\"FINE_GRAINED_EVAL\"] = \"1\"\n",
    "# model = build_model()\n",
    "# run_test(model, resolution_idx, loaded_nusc, streaming=streaming, forecasting=forecasting, sched_period_ms=2000)\n",
    "# result_str = do_eval(sampled_objects, resolution_idx, model.dataset, exec_times_musec=exec_times_musec,\n",
    "#                              dump_eval_dict=streaming, loaded_nusc=loaded_nusc)\n",
    "# print(result_str)\n",
    "\n",
    "if True:\n",
    "    streaming = True\n",
    "    offline = False\n",
    "    results = []\n",
    "    num_res = 5\n",
    "    for forecasting in (False,): # True):\n",
    "        # os.environ[\"FINE_GRAINED_EVAL\"] = \"1\" if forecasting else \"0\"\n",
    "        # with concurrent.futures.ProcessPoolExecutor(max_workers=num_res, mp_context=mp_context) as executor:\n",
    "            for resolution_idx in range(num_res):\n",
    "                model = build_model()\n",
    "                run_test(model, resolution_idx, loaded_nusc, streaming=streaming, forecasting=forecasting, sched_period_ms=2000)\n",
    "            \n",
    "                with open(f'tmp_results/detdata_res{model.res_idx}.pkl', 'rb') as f:\n",
    "                    sampled_objects, exec_times_musec, resolution_stats = pickle.load(f)\n",
    "                    print(f'Loaded {len(sampled_objects)} objects from file.')\n",
    "    \n",
    "                exec_times_musec = None if (streaming or offline) else exec_times_musec\n",
    "                # fut = executor.submit(\n",
    "                result_str = do_eval(sampled_objects, resolution_idx, model.dataset, exec_times_musec=exec_times_musec,\n",
    "                                     dump_eval_dict=streaming, loaded_nusc=loaded_nusc)\n",
    "                results.append([resolution_idx, forecasting, resolution_stats, result_str])\n",
    "            # for r in range(1, num_res+1):\n",
    "                result = results[-1]\n",
    "                # result[3] = result[3].result()\n",
    "                print(f'Resolution index: {result[0]}')\n",
    "                print(f'Forecasting: {forecasting}')\n",
    "                print(f'Resolution stats: {result[2]}')\n",
    "                print(result[3])\n",
    "\n",
    "    \n",
    "    with open(\"output_offline.txt\", \"w\") as f:\n",
    "        for resolution_idx, forecasting, resolution_stats, result_str in results:\n",
    "            if forecasting:\n",
    "                f.write('FORECASTING WAS UTILIZED\\n')\n",
    "            f.write(f'{resolution_stats}\\n')\n",
    "            f.write(result_str)\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
