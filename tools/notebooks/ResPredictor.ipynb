{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e79a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/root/shared/Anytime-Lidar/tools\")\n",
    "os.environ[\"DATASET_PERIOD\"] = \"50\"\n",
    "os.environ[\"PMODE\"] = \"pmode_0002\" # same as jetson orin\n",
    "os.environ[\"STREVAL\"] = \"1\"\n",
    "os.environ[\"CALIBRATION\"] = \"0\"\n",
    "\n",
    "import _init_path\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "from eval_utils import eval_utils\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.utils import common_utils\n",
    "from pcdet.models.model_utils.tensorrt_utils.trtwrapper import TRTWrapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import res_pred_utils\n",
    "import nuscenes\n",
    "import importlib\n",
    "# import numba\n",
    "import concurrent.futures\n",
    "\n",
    "def get_dataset(cfg):\n",
    "    log_file = './tmp_results/log_eval_%s' % datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    log_file = log_file + str(np.random.randint(0, 9999)) + '.txt'\n",
    "    logger = common_utils.create_logger(log_file, rank=0)\n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, batch_size=1,\n",
    "        dist=False, workers=0, logger=logger, training=False\n",
    "    )\n",
    "\n",
    "    return logger, test_set, test_loader, sampler\n",
    "\n",
    "def calc_tail_ms(cur_time_point_ms, data_period_ms):\n",
    "    return cur_time_point_ms - math.floor(cur_time_point_ms / data_period_ms) * data_period_ms\n",
    "\n",
    "def build_model():\n",
    "    cfg_file = \"./cfgs/nuscenes_models/pillar01_015_02_024_03_valor.yaml\"\n",
    "    cfg_from_yaml_file(cfg_file, cfg)\n",
    "    \n",
    "    set_cfgs = ['MODEL.METHOD', '0', 'MODEL.DEADLINE_SEC', '100.0', 'MODEL.DENSE_HEAD.NAME', 'CenterHeadInf',\n",
    "                'OPTIMIZATION.BATCH_SIZE_PER_GPU', '1']\n",
    "    cfg_from_list(set_cfgs, cfg)\n",
    "    logger, test_set, test_loader, sampler = get_dataset(cfg)\n",
    "    print(f'Loaded dataset with {len(test_set)} samples')\n",
    "    \n",
    "    ckpt_file=\"../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth\"\n",
    "    \n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "    model.load_params_from_file(filename=ckpt_file, logger=logger, to_cpu=False)\n",
    "    # model.pre_hook_handle.remove()\n",
    "    # model.post_hook_handle.remove()\n",
    "    model.eval() # should be run with @torch.no_grad\n",
    "    model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "@torch.jit.script\n",
    "def move_bounding_boxes(bboxes, egovel, time_diffs_sec):\n",
    "    outp_shape = (time_diffs_sec.shape[0], bboxes.shape[0], bboxes.shape[1])\n",
    "    outp_bboxes = torch.empty(outp_shape, dtype=bboxes.dtype)\n",
    "    outp_bboxes[:, :, 2:] = bboxes[:, 2:]\n",
    "\n",
    "    for t in range(time_diffs_sec.shape[0]):\n",
    "        outp_bboxes[t, :, :2] = bboxes[:, :2] + (bboxes[:, 7:9] - egovel) * time_diffs_sec[t]\n",
    "\n",
    "    return outp_bboxes\n",
    "\n",
    "def run_test(model, resolution_idx, loaded_nusc, streaming=True, forecasting=False, sched_period_ms=2000, collect_res_pred_data=False):\n",
    "    print('***********************')\n",
    "    print(f'***RESOLUTION INDEX {resolution_idx}**')\n",
    "    print('***********************')\n",
    "\n",
    "    data_period_ms = int(os.environ[\"DATASET_PERIOD\"])\n",
    "    num_samples = len(model.dataset)\n",
    "\n",
    "    cur_sample_idx = 0\n",
    "    sim_cur_time_ms = 0.\n",
    "    last_exec_time_ms = 100.\n",
    "    target_sched_time_ms = 0.\n",
    "    sampled_dets = [None] * num_samples\n",
    "    exec_times_ms = []\n",
    "    # sample_tokens = []\n",
    "    resolution_stats = [0] * model.num_res\n",
    "\n",
    "    model.calibrate()\n",
    "    do_res_sched = (resolution_idx == -1)\n",
    "    model.res_idx = 0 if do_res_sched else resolution_idx\n",
    "\n",
    "    # if collect_res_pred_data:\n",
    "    #     res_data_scene_name = [None] * num_samples\n",
    "    #     res_data_inps = [None] * num_samples\n",
    "    #     res_data_tp_fp_gt = torch.empty((num_samples, model.num_res, model.num_class, 4, 3)) # 4 dist thresholds, 3 tp fp gt\n",
    "\n",
    "    if do_res_sched:\n",
    "        trt_path = f\"./deploy_files/trt_engines/pmode_0000/resolution_pred_mdl.engine\"\n",
    "        print('Trying to load trt engine at', trt_path)\n",
    "        res_pred_trt = TRTWrapper(trt_path, ['objcount_and_egovel'], ['res_scores'])\n",
    "        res_pred_out_buf = None\n",
    "\n",
    "    model.prev_scene_token = model.token_to_scene[model.dataset.infos[cur_sample_idx]['token']]\n",
    "    with alive_bar(num_samples, force_tty=True, max_cols=160, manual=True) as bar:\n",
    "        while cur_sample_idx < num_samples:\n",
    "            # Check if we are in a new scene, reset if we are\n",
    "            if streaming:\n",
    "                potential_sample_tkn = model.dataset.infos[cur_sample_idx]['token']\n",
    "                scene_token = model.token_to_scene[potential_sample_tkn]\n",
    "                if model.prev_scene_token != scene_token:\n",
    "                    target_sched_time_ms = 0.\n",
    "                    while model.prev_scene_token != scene_token:\n",
    "                        cur_sample_idx -= 1\n",
    "                        potential_sample_tkn = model.dataset.infos[cur_sample_idx]['token']\n",
    "                        scene_token = model.token_to_scene[potential_sample_tkn]\n",
    "                    cur_sample_idx += 1\n",
    "                    sim_cur_time_ms = cur_sample_idx * data_period_ms\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # if collect_res_pred_data:\n",
    "                #     for res in range(model.num_res):\n",
    "                #         model.res_idx = res\n",
    "                #         pred_dicts, ret_dict = model([cur_sample_idx])\n",
    "                #         lbd = model.latest_batch_dict\n",
    "                #         if res == resolution_idx and cur_sample_idx % 10 == 0: # every 1 secs\n",
    "                #             shr_conv_outp = lbd['shr_conv_outp'].cpu()\n",
    "                #             res_data_inps[cur_sample_idx] = (shr_conv_outp, *(lbd['tensor_slice_inds']))\n",
    "\n",
    "                #         pd = lbd['final_box_dicts'][0]\n",
    "                #         gt_boxes = lbd['gt_boxes'].cpu()\n",
    "                #         res_data_tp_fp_gt[cur_sample_idx, res] = res_pred_utils.get_tp_fp_gt(\n",
    "                #                     pd['pred_boxes'], pd['pred_scores'], pd['pred_labels'],\n",
    "                #                     gt_boxes[0, :, :-1], gt_boxes[0, :, -1], model.num_class)\n",
    "\n",
    "                #     scene_name = model.token_to_scene_name[lbd['metadata'][0]['token']]\n",
    "                #     res_data_scene_name[cur_sample_idx] = scene_name\n",
    "                # else:\n",
    "                lbd = model.latest_batch_dict # save bef its modified\n",
    "                pred_dicts, ret_dict = model([cur_sample_idx])\n",
    "\n",
    "            # Predict the execution time as if the DNN were to be executed on target platform\n",
    "            batch_dict = model.latest_batch_dict\n",
    "            num_points = batch_dict['points'].size(0)\n",
    "            num_voxels = np.array([batch_dict['bb3d_num_voxels']])\n",
    "            xlen = batch_dict['tensor_slice_inds'][1] - batch_dict['tensor_slice_inds'][0]\n",
    "            last_exec_time_ms = model.calibrators[model.res_idx].pred_exec_time_ms(\n",
    "               num_points, num_voxels, xlen)\n",
    "\n",
    "            sample_tkn = batch_dict['metadata'][0]['token']\n",
    "            if lbd is not None and not batch_dict['scene_reset']:\n",
    "                prev_sample_tkn = lbd['metadata'][0]['token']\n",
    "                egovel = res_pred_utils.get_2d_egovel(\n",
    "                        model.token_to_ts[prev_sample_tkn],\n",
    "                        model.token_to_pose[prev_sample_tkn],\n",
    "                        model.token_to_ts[sample_tkn],\n",
    "                        model.token_to_pose[sample_tkn])\n",
    "            else: # assume its zero\n",
    "                egovel = np.zeros(2)\n",
    "\n",
    "            exec_times_ms.append((sample_tkn, last_exec_time_ms))\n",
    "            if not streaming:\n",
    "                # sim_cur_time_ms += data_period_ms # unnecessary\n",
    "                sampled_dets[cur_sample_idx] = pred_dicts\n",
    "            else:\n",
    "                # the sampled_dets can be overwritten, which is okay\n",
    "                sim_cur_time_ms += last_exec_time_ms\n",
    "                num_to_forecast = 500 // data_period_ms\n",
    "                future_sample_inds = [(sim_cur_time_ms+(i*data_period_ms))//data_period_ms for i in range(1,num_to_forecast+1)]\n",
    "                future_sample_inds = torch.tensor([ind for ind in future_sample_inds if ind < num_samples]).int()\n",
    "                if forecasting: # NOTE consider the overhead here\n",
    "                    # Forecast for next 500 ms\n",
    "                    time_diffs_sec = (future_sample_inds * data_period_ms - (sim_cur_time_ms - last_exec_time_ms)) * 1e-3\n",
    "                    outp_bboxes_all = move_bounding_boxes(pred_dicts[0]['pred_boxes'], torch.from_numpy(egovel), time_diffs_sec)\n",
    "                    for outp_bboxes, sample_ind_f in zip(outp_bboxes_all, future_sample_inds.tolist()):\n",
    "                        forecasted_pd = {k : pred_dicts[0][k] for k in ('pred_scores', 'pred_labels')}\n",
    "                        forecasted_pd['pred_boxes'] = outp_bboxes\n",
    "                        sampled_dets[sample_ind_f] = [forecasted_pd]\n",
    "                else:\n",
    "                    for sample_ind_f in future_sample_inds.tolist():\n",
    "                        sampled_dets[sample_ind_f] = pred_dicts\n",
    "\n",
    "            if do_res_sched and sim_cur_time_ms >= target_sched_time_ms:\n",
    "                lbl_dist = torch.bincount(pred_dicts[0]['pred_labels'] - 1, minlength=10).float() / 100.0\n",
    "                inp_tensor = torch.tensor(lbl_dist.tolist() + [np.linalg.norm(egovel).item()/15.0], dtype=torch.float).unsqueeze(0)\n",
    "                inp_tensor[torch.isnan(inp_tensor)] = 0.\n",
    "                res_pred_out_buf = res_pred_trt({'objcount_and_egovel': inp_tensor.cuda()},\n",
    "                    res_pred_out_buf) \n",
    "                res_scores = res_pred_out_buf['res_scores'].cpu()\n",
    "\n",
    "                _, chosen_res = torch.max(res_scores, 1)\n",
    "                model.res_idx = chosen_res.item()\n",
    "\n",
    "                #NOTE I need to consider the sched time as well and add to sim cur time ms\n",
    "                target_sched_time_ms += sched_period_ms\n",
    "                resolution_stats[model.res_idx] += 1\n",
    "\n",
    "            #Dynamic scheduling\n",
    "            if streaming:\n",
    "                cur_tail = calc_tail_ms(sim_cur_time_ms, data_period_ms)\n",
    "                pred_finish_time = sim_cur_time_ms + last_exec_time_ms #NOTE I can also use mean exec time\n",
    "                next_tail = calc_tail_ms(pred_finish_time, data_period_ms)\n",
    "                if next_tail < cur_tail:\n",
    "                    # Sleep, extra 1 ms is added to make sure sleep time is enough\n",
    "                    sim_cur_time_ms += data_period_ms - cur_tail + 1\n",
    "\n",
    "                next_sample_idx = int(sim_cur_time_ms / data_period_ms)\n",
    "            else:\n",
    "                next_sample_idx = cur_sample_idx + 1\n",
    "\n",
    "            if cur_sample_idx == next_sample_idx:\n",
    "                print(f'ERROR, trying to process already processed sample {next_sample_idx}')\n",
    "\n",
    "            cur_sample_idx = next_sample_idx\n",
    "            bar(cur_sample_idx / num_samples)\n",
    "\n",
    "    # if collect_res_pred_data:\n",
    "    #     with open(f'res_pred_dataset_v2.pkl', 'wb') as f:\n",
    "    #         pickle.dump({\n",
    "    #             'res_data_scene_name': res_data_scene_name,\n",
    "    #             'res_data_inps': res_data_inps,\n",
    "    #             'res_data_tp_fp_gt': res_data_tp_fp_gt\n",
    "    #         }, f)\n",
    "    #         print('Dumped the res pred dataset!')\n",
    "\n",
    "    if do_res_sched:\n",
    "        model.res_idx = -1\n",
    "    model.print_time_stats()\n",
    "    print('Resolution selection stats:')\n",
    "    print(resolution_stats)\n",
    "\n",
    "    exec_times_musec = {st:(et*1000) for st, et in exec_times_ms}\n",
    "\n",
    "    with open(f'tmp_results/detdata_res{model.res_idx}.pkl', 'wb') as f:\n",
    "        pickle.dump([sampled_dets, exec_times_musec, resolution_stats], f)\n",
    "\n",
    "    print(f'Sampled {len(sampled_dets)} objects')\n",
    "    return sampled_dets, exec_times_musec, resolution_stats\n",
    "\n",
    "def do_eval(sampled_objects, resolution_idx, dataset, exec_times_musec=None, dump_eval_dict=True, loaded_nusc=None):\n",
    "    #Convert them to openpcdet format\n",
    "    os.environ[\"RESOLUTION_IDX\"] = str(resolution_idx)\n",
    "\n",
    "    det_annos = []\n",
    "    num_ds_elems = len(dataset)\n",
    "    for i in range(num_ds_elems):\n",
    "        data_dict = dataset.get_metadata_dict(i)\n",
    "        for k, v in data_dict.items():\n",
    "            data_dict[k] = [v] # make it a batch dict\n",
    "        pred_dicts = sampled_objects[i]\n",
    "\n",
    "        if pred_dicts is None:\n",
    "            pred_dicts = [{\n",
    "                'pred_boxes': torch.empty((0, 9)),\n",
    "                'pred_scores': torch.empty(0),\n",
    "                'pred_labels': torch.empty(0, dtype=torch.long)\n",
    "            }]\n",
    "        data_dict['final_box_dicts'] = pred_dicts\n",
    "        det_annos += dataset.generate_prediction_dicts(\n",
    "            data_dict, data_dict['final_box_dicts'], dataset.class_names, output_path=None\n",
    "        )\n",
    "\n",
    "    #nusc_annos = {} # not needed but keep it anyway\n",
    "    streaming = (len(exec_times_musec) != len(dataset))\n",
    "    print('STREAMING EVAL' if streaming else 'OFFLINE EVAL')\n",
    "    result_str, result_dict = dataset.evaluation(\n",
    "        det_annos, dataset.class_names,\n",
    "        eval_metric='kitti', #model.model_cfg.POST_PROCESSING.EVAL_METRIC,\n",
    "        output_path='./tmp_results',\n",
    "        boxes_in_global_coords=False,\n",
    "        loaded_nusc=loaded_nusc,\n",
    "        det_elapsed_musec=None, #(None if streaming else exec_times_musec)\n",
    "    )\n",
    "\n",
    "    if dump_eval_dict:\n",
    "        eval_d = {\n",
    "                'cfg': cfg,\n",
    "                'exec_times_musec': exec_times_musec,\n",
    "                'det_annos': det_annos,\n",
    "                'annos_in_glob_coords': False,\n",
    "                'resolution': resolution_idx,\n",
    "                'result_str': result_str,\n",
    "        }\n",
    "\n",
    "        with open(f'sampled_dets_res{resolution_idx}.pkl', 'wb') as f:\n",
    "            pickle.dump(eval_d, f)\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddfaa6-57c6-463c-bbaa-1bf8bea6f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "\n",
    "dataset_version = 'v1.0-trainval'\n",
    "root_path = \"../data/nuscenes/\" + dataset_version\n",
    "loaded_nusc = NuScenes(version=dataset_version, dataroot=root_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2514a64d-d54d-4bfd-8f58-aba7f054efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pcdet\n",
    "# import nuscenes.eval.detection.algo\n",
    "# import nuscenes.eval.detection.evaluate\n",
    "# importlib.reload(nuscenes.eval.detection.algo)\n",
    "# importlib.reload(nuscenes.eval.detection.evaluate)\n",
    "# importlib.reload(nuscenes.utils.data_classes)\n",
    "\n",
    "\n",
    "# Run test\n",
    "# resolution_idx = 0\n",
    "# streaming = False\n",
    "# forecasting = False\n",
    "# model = build_model()\n",
    "# res_pred_mdl = res_pred_utils.ResolutionPredictor(model.num_res)\n",
    "# sampled_objects, exec_times_musec, resolution_stats = run_test(model, resolution_idx, loaded_nusc,\n",
    "                            # streaming=streaming, forecasting=forecasting, sched_period_ms=2000, collect_res_pred_data=True)\n",
    "# result_str = do_eval(sampled_objects, resolution_idx, model.dataset, exec_times_musec=exec_times_musec,\n",
    "#                              dump_eval_dict=False, loaded_nusc=loaded_nusc)\n",
    "# print(result_str)\n",
    "\n",
    "if True:\n",
    "    streaming = True\n",
    "    offline = not streaming\n",
    "    results = []\n",
    "    num_res = 5\n",
    "    skip_eval=False\n",
    "    forecasting=True # ignored if offline\n",
    "    for resolution_idx in [1]: #range(num_res):\n",
    "        os.environ[\"FINE_GRAINED_EVAL\"] = (\"1\" if resolution_idx >= 0 else \"0\")\n",
    "        t1 = time.time()\n",
    "        model = build_model()\n",
    "\n",
    "        sampled_objects, exec_times_musec, resolution_stats = run_test(model, resolution_idx, \n",
    "                                                                    loaded_nusc, streaming=streaming, \n",
    "                                                                    forecasting=forecasting, sched_period_ms=2000)\n",
    "        if not skip_eval:\n",
    "            # fname = f'tmp_results/detdata_res{resolution_idx}.pkl'\n",
    "            # with open(fname, 'rb') as f:\n",
    "            #     sampled_objects, exec_times_musec, resolution_stats = pickle.load(f)\n",
    "            #     print(f'Loaded {len(sampled_objects)} objects from {fname}')\n",
    "\n",
    "            dataset = model.dataset\n",
    "            del model\n",
    "            result_str = do_eval(sampled_objects, resolution_idx, dataset, exec_times_musec=exec_times_musec,\n",
    "                                 dump_eval_dict=True, loaded_nusc=loaded_nusc)\n",
    "            results.append([resolution_idx, forecasting, resolution_stats, result_str])\n",
    "            result = results[-1]\n",
    "            print(f'Resolution index: {result[0]}')\n",
    "            print(f'Forecasting: {forecasting}')\n",
    "            print(f'Resolution stats: {result[2]}')\n",
    "            print(result[3])\n",
    "        t2 = time.time()\n",
    "        print('Time passed (seconds):', t2-t1)\n",
    "    if not skip_eval:\n",
    "        with open(f\"output_streaming_{streaming}.txt\", \"w\") as f:\n",
    "            for resolution_idx, forecasting, resolution_stats, result_str in results:\n",
    "                if forecasting:\n",
    "                    f.write('FORECASTING WAS UTILIZED\\n')\n",
    "                f.write(f'{resolution_stats}\\n')\n",
    "                f.write(result_str)\n",
    "                f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
