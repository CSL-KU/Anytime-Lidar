{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ef89b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DATASET_PERIOD\"] = \"100\"\n",
    "os.environ[\"PMODE\"] = \"pmode_0003\" # same as jetson orin\n",
    "os.environ[\"STREVAL_TRAIN\"] = \"1\"\n",
    "os.environ[\"FINE_GRAINED_EVAL\"] = \"1\"\n",
    "\n",
    "os.chdir(\"/root/shared/Anytime-Lidar/tools\")\n",
    "\n",
    "import _init_path\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "from eval_utils import eval_utils\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_dataset(cfg):\n",
    "    log_file = ('./tmp_results/log_eval_%s.txt' % datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "    logger = common_utils.create_logger(log_file, rank=0)\n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, batch_size=1,\n",
    "        dist=False, workers=0, logger=logger, training=False\n",
    "    )\n",
    "\n",
    "    return logger, test_set, test_loader, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71556ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 17:53:31,305   INFO  Loading NuScenes dataset\n",
      "2024-10-29 17:53:33,855   INFO  Total samples for NuScenes dataset: 27332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 27332 samples\n",
      "Default deadline is: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 17:53:34,845   INFO  ==> Loading parameters from checkpoint ../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth to GPU\n",
      "2024-10-29 17:53:36,199   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+31546c7+py52e9ef4\n",
      "2024-10-29 17:53:36,236   INFO  ==> Done (loaded 2106/2106)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "72.12\t74.36\t80.09\t114.91\t146.66\t155.11\t159.81\n",
      "Calibrating resolution 0\n",
      "Resolution idx: 0 Input: x_conv4 torch.Size([1, 256, 144, 144])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res0.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res0.engine successfully loaded.\n",
      "Optimization took 1.6199960708618164 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "55.12\t56.88\t62.96\t76.96\t91.30\t93.92\t104.57\n",
      "Calibrating resolution 1\n",
      "Resolution idx: 1 Input: x_conv4 torch.Size([1, 256, 96, 96])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res1.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res1.engine successfully loaded.\n",
      "Optimization took 0.7895388603210449 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "53.13\t53.49\t54.85\t63.97\t74.60\t75.79\t79.51\n",
      "Calibrating resolution 2\n",
      "Resolution idx: 2 Input: x_conv4 torch.Size([1, 256, 72, 72])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res2.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res2.engine successfully loaded.\n",
      "Optimization took 0.4405360221862793 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "48.71\t50.83\t51.81\t58.51\t63.08\t64.38\t71.86\n",
      "Calibrating resolution 3\n",
      "Resolution idx: 3 Input: x_conv4 torch.Size([1, 256, 60, 60])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res3.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res3.engine successfully loaded.\n",
      "Optimization took 0.46836113929748535 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "End to end execution time stats (ms):\n",
      "Min\t1Perc\t5Perc\tMean\t95Perc\t99Perc\tMax\n",
      "48.80\t49.11\t50.34\t54.84\t58.31\t61.89\t70.56\n",
      "Calibrating resolution 4\n",
      "Resolution idx: 4 Input: x_conv4 torch.Size([1, 256, 48, 48])\n",
      "Trying to load trt engine at ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res4.engine\n",
      "TensorRT engine ./deploy_files/trt_engines/pmode_0003/pillarnet01_valo_dense_convs_res4.engine successfully loaded.\n",
      "Optimization took 0.4593970775604248 seconds.\n",
      "Num params: 15325638\n",
      "Num params trainable: 15325638\n",
      "Detector3D calibration done\n",
      "|████████▉                               | ▇▅▃ 22% [6080/27332] in 1:29 (~5:10, 68.1/s) "
     ]
    }
   ],
   "source": [
    "cfg_file = \"./cfgs/nuscenes_models/pillar01_015_02_024_03_valor.yaml\"\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "\n",
    "set_cfgs = ['MODEL.METHOD', '0', 'MODEL.DEADLINE_SEC', '100.0', 'MODEL.DENSE_HEAD.NAME', 'CenterHeadInf', 'OPTIMIZATION.BATCH_SIZE_PER_GPU', '1']\n",
    "cfg_from_list(set_cfgs, cfg)\n",
    "logger, test_set, test_loader, sampler = get_dataset(cfg)\n",
    "print(f'Loaded dataset with {len(test_set)} samples')\n",
    "\n",
    "def calc_tail_ms(cur_time_point_ms, data_period_ms):\n",
    "    return cur_time_point_ms - math.floor(cur_time_point_ms / data_period_ms) * data_period_ms\n",
    "\n",
    "ckpt_file=\"../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth\"\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "model.load_params_from_file(filename=ckpt_file, logger=logger, to_cpu=False)\n",
    "# model.pre_hook_handle.remove()\n",
    "# model.post_hook_handle.remove()\n",
    "model.eval() # should be run with @torch.no_grad\n",
    "model.cuda()\n",
    "\n",
    "data_period_ms = 50\n",
    "num_samples = len(test_set)\n",
    "\n",
    "last_sample_idx = 0\n",
    "cur_sample_idx = 0\n",
    "sim_cur_time_ms = 0.\n",
    "last_exec_time_ms = 100.\n",
    "pred_dicts_arr = []\n",
    "output_times_ms = []\n",
    "processed_inds = set()\n",
    "\n",
    "model.calibrate()\n",
    "model.res_idx = 2\n",
    "\n",
    "with alive_bar(num_samples, force_tty=True, max_cols=160, manual=True) as bar:\n",
    "    while cur_sample_idx < num_samples:\n",
    "        with torch.no_grad():\n",
    "            #batch_dict = model.dataset.collate_batch([data_dict])\n",
    "            #load_data_to_gpu(batch_dict)\n",
    "            pred_dicts, ret_dict = model([cur_sample_idx])\n",
    "\n",
    "        # Predict the execution time as if the DNN were to be executed on target platform\n",
    "        batch_dict = model.latest_batch_dict\n",
    "        last_exec_time_ms = model.calibrators[model.res_idx].pred_exec_time_ms(\n",
    "           batch_dict['points'].size(0),\n",
    "           np.array([batch_dict['bb3d_num_voxels']]),\n",
    "           batch_dict['x_lims'][1] - batch_dict['x_lims'][0])\n",
    "\n",
    "        sim_cur_time_ms += last_exec_time_ms\n",
    "        pred_dicts_arr.append(pred_dicts) # last one is output time\n",
    "        output_times_ms.append(sim_cur_time_ms)\n",
    "        processed_inds.add(cur_sample_idx)\n",
    "\n",
    "        #Dynamic scheduling\n",
    "        cur_tail = calc_tail_ms(sim_cur_time_ms, data_period_ms)\n",
    "        pred_finish_time = sim_cur_time_ms + last_exec_time_ms #NOTE I can also use mean exec time\n",
    "        next_tail = calc_tail_ms(pred_finish_time, data_period_ms)\n",
    "        if next_tail < cur_tail:\n",
    "            # Sleep, extra 1 ms is added to make sure sleet time is enough\n",
    "            sim_cur_time_ms += data_period_ms - cur_tail + 1\n",
    "\n",
    "        cur_sample_idx = int(sim_cur_time_ms / data_period_ms)\n",
    "        if cur_sample_idx in processed_inds:\n",
    "            print(f'ERROR, trying to process already processed sample {cur_sample_idx}')\n",
    "\n",
    "        bar(cur_sample_idx / num_samples)\n",
    "        last_sample_idx = cur_sample_idx\n",
    "\n",
    "output_times_ms = np.array(output_times_ms)\n",
    "model.print_time_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# det_annos = []\n",
    "# for bd, pred_dicts, outp_time_point in pred_tuples:\n",
    "#     annos = dataset.generate_prediction_dicts(\n",
    "#         bd, pred_dicts, class_names, output_path=op\n",
    "#     )\n",
    "#     det_annos += annos\n",
    "\n",
    "#We have:\n",
    "# pred_dicts_arr\n",
    "# output_times_ms\n",
    "# processed_inds\n",
    "\n",
    "def get_streaming_eval_samples(num_ds_elems : int, period_ms : int, output_times_ms : np.ndarray, pred_dicts_arr):\n",
    "    # Streaming eval\n",
    "    #Now do manual sampling base on time\n",
    "\n",
    "    #times_ns should be output_times_ms\n",
    "    sampled_objects = []\n",
    "    for i in range(num_ds_elems):\n",
    "        sample_time_ms = i*period_ms\n",
    "        aft = output_times_ms > sample_time_ms\n",
    "        if aft[0] == True:\n",
    "            sampled_objects.append(None) # Should be an empty pred dicts arr\n",
    "#             print('0', end=' ')\n",
    "        elif aft[-1] == False:\n",
    "            sampled_objects.append(pred_dicts_arr[-1])\n",
    "#             print('-1', end=' ')\n",
    "        else:\n",
    "            sample_idx = np.argmax(aft) - 1\n",
    "            sampled_objects.append(pred_dicts_arr[sample_idx])\n",
    "#             print(sample_idx, end=' ')\n",
    "#     print()\n",
    "\n",
    "    return sampled_objects\n",
    "\n",
    "def do_eval(sampled_objects, dataset):\n",
    "    #Convert them to openpcdet format\n",
    "\n",
    "    det_annos = []\n",
    "    num_ds_elems = len(dataset)\n",
    "    for i in range(num_ds_elems):\n",
    "        data_dict = dataset.get_metadata_dict(i)\n",
    "        for k, v in data_dict.items():\n",
    "            data_dict[k] = [v] # make it a batch dict\n",
    "        pred_dicts = sampled_objects[i]\n",
    "\n",
    "        if pred_dicts is None:\n",
    "            pred_dicts = [{\n",
    "                'pred_boxes': torch.empty((0, 9)),\n",
    "                'pred_scores': torch.empty(0),\n",
    "                'pred_labels': torch.empty(0, dtype=torch.long)\n",
    "            }]\n",
    "        data_dict['final_box_dicts'] = pred_dicts\n",
    "        det_annos += dataset.generate_prediction_dicts(\n",
    "            data_dict, data_dict['final_box_dicts'], dataset.class_names, output_path=None\n",
    "        )\n",
    "\n",
    "    calib_dl = model.res_idx\n",
    "    eval_d = {\n",
    "        'cfg': cfg,\n",
    "        'det_annos': det_annos,\n",
    "        'annos_in_glob_coords': False,\n",
    "        'calib_deadline_ms': model.res_idx}\n",
    "\n",
    "    #nusc_annos = {} # not needed but keep it anyway\n",
    "    result_str, result_dict = dataset.evaluation(\n",
    "        det_annos, dataset.class_names,\n",
    "        eval_metric=cfg.MODEL.POST_PROCESSING.EVAL_METRIC,\n",
    "        output_path='./tmp_results',\n",
    "        boxes_in_global_coords=False,\n",
    "    )\n",
    "\n",
    "    print(result_str)\n",
    "    eval_d['result_str'] = result_str\n",
    "\n",
    "    with open(f'eval_data_{calib_dl}ms.pkl', 'wb') as f:\n",
    "        pickle.dump(eval_d, f)\n",
    "\n",
    "sampled_objects = get_streaming_eval_samples(len(test_set), data_period_ms, output_times_ms, pred_dicts_arr)\n",
    "print(f'Sampled {len(sampled_objects)} objects')\n",
    "do_eval(sampled_objects, model.dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
