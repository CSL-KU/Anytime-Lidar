{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e79a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/root/shared/Anytime-Lidar/tools\")\n",
    "os.environ[\"DATASET_PERIOD\"] = \"50\"\n",
    "os.environ[\"PMODE\"] = \"pmode_0002\" # same as jetson orin\n",
    "os.environ[\"STREVAL_TRAIN\"] = \"1\"\n",
    "\n",
    "import _init_path\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "from eval_utils import eval_utils\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.utils import common_utils\n",
    "from pcdet.models.model_utils.tensorrt_utils.trtwrapper import TRTWrapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import res_pred_utils\n",
    "import nuscenes\n",
    "import importlib\n",
    "# import numba\n",
    "import concurrent.futures\n",
    "\n",
    "def get_dataset(cfg):\n",
    "    log_file = './tmp_results/log_eval_%s' % datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    log_file = log_file + str(np.random.randint(0, 9999)) + '.txt'\n",
    "    logger = common_utils.create_logger(log_file, rank=0)\n",
    "    test_set, test_loader, sampler = build_dataloader(\n",
    "        dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, batch_size=1,\n",
    "        dist=False, workers=0, logger=logger, training=False\n",
    "    )\n",
    "\n",
    "    return logger, test_set, test_loader, sampler\n",
    "\n",
    "def calc_tail_ms(cur_time_point_ms, data_period_ms):\n",
    "    return cur_time_point_ms - math.floor(cur_time_point_ms / data_period_ms) * data_period_ms\n",
    "\n",
    "def build_model():\n",
    "    cfg_file = \"./cfgs/nuscenes_models/pillar01_015_02_024_03_valor.yaml\"\n",
    "    cfg_from_yaml_file(cfg_file, cfg)\n",
    "    \n",
    "    set_cfgs = ['MODEL.METHOD', '0', 'MODEL.DEADLINE_SEC', '100.0', 'MODEL.DENSE_HEAD.NAME', 'CenterHeadInf',\n",
    "                'OPTIMIZATION.BATCH_SIZE_PER_GPU', '1']\n",
    "    cfg_from_list(set_cfgs, cfg)\n",
    "    logger, test_set, test_loader, sampler = get_dataset(cfg)\n",
    "    print(f'Loaded dataset with {len(test_set)} samples')\n",
    "    \n",
    "    ckpt_file=\"../output/nuscenes_models/pillar01_015_02_024_03_valor/default/ckpt/checkpoint_epoch_30.pth\"\n",
    "    \n",
    "    model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "    model.load_params_from_file(filename=ckpt_file, logger=logger, to_cpu=False)\n",
    "    # model.pre_hook_handle.remove()\n",
    "    # model.post_hook_handle.remove()\n",
    "    model.eval() # should be run with @torch.no_grad\n",
    "    model.cuda()\n",
    "\n",
    "    return model\n",
    "\n",
    "@torch.jit.script\n",
    "def move_bounding_boxes(bboxes, egovel, time_diffs_sec):\n",
    "    outp_shape = (time_diffs_sec.shape[0], bboxes.shape[0], bboxes.shape[1])\n",
    "    outp_bboxes = torch.empty(outp_shape, dtype=bboxes.dtype)\n",
    "    outp_bboxes[:, :, 2:] = bboxes[:, 2:]\n",
    "\n",
    "    for t in range(time_diffs_sec.shape[0]):\n",
    "        outp_bboxes[t, :, :2] = bboxes[:, :2] + (bboxes[:, 7:9] - egovel) * time_diffs_sec[t]\n",
    "\n",
    "    return outp_bboxes\n",
    "\n",
    "def run_test(model, resolution_idx, loaded_nusc, streaming=True, forecasting=False, sched_period_ms=2000):\n",
    "    print('***********************')\n",
    "    print(f'***RESOLUTION INDEX {resolution_idx}**')\n",
    "    print('***********************')\n",
    "\n",
    "    data_period_ms = int(os.environ[\"DATASET_PERIOD\"])\n",
    "    num_samples = len(model.dataset)\n",
    "\n",
    "    cur_sample_idx = 0\n",
    "    sim_cur_time_ms = 0.\n",
    "    last_exec_time_ms = 100.\n",
    "    target_sched_time_ms = 0.\n",
    "    sampled_dets = [None] * num_samples\n",
    "    exec_times_ms = []\n",
    "    # sample_tokens = []\n",
    "    resolution_stats = [0] * model.num_res\n",
    "\n",
    "    model.calibrate()\n",
    "    do_res_sched = (resolution_idx == -1)\n",
    "    model.res_idx = 0 if do_res_sched else resolution_idx\n",
    "\n",
    "    if do_res_sched:\n",
    "        trt_path = f\"./deploy_files/trt_engines/pmode_0000/resolution_pred_mdl.engine\"\n",
    "        print('Trying to load trt engine at', trt_path)\n",
    "        res_pred_trt = TRTWrapper(trt_path, ['objcount_and_egovel'], ['res_scores'])\n",
    "        res_pred_out_buf = None\n",
    "\n",
    "    with alive_bar(num_samples, force_tty=True, max_cols=160, manual=True) as bar:\n",
    "        while cur_sample_idx < num_samples:\n",
    "            with torch.no_grad():\n",
    "                lbd = model.latest_batch_dict # save bef its modified\n",
    "\n",
    "                pred_dicts, ret_dict = model([cur_sample_idx])\n",
    "\n",
    "            # Predict the execution time as if the DNN were to be executed on target platform\n",
    "            batch_dict = model.latest_batch_dict\n",
    "            num_points = batch_dict['points'].size(0)\n",
    "            num_voxels = np.array([batch_dict['bb3d_num_voxels']])\n",
    "            xlen = batch_dict['x_lims'][1] - batch_dict['x_lims'][0]\n",
    "            last_exec_time_ms = model.calibrators[model.res_idx].pred_exec_time_ms(\n",
    "               num_points, num_voxels, xlen)\n",
    "\n",
    "            sample_tkn = batch_dict['metadata'][0]['token']\n",
    "            if lbd is not None and not batch_dict['scene_reset']:\n",
    "                prev_sample_tkn = lbd['metadata'][0]['token']\n",
    "                egovel = res_pred_utils.get_2d_egovel(\n",
    "                        model.token_to_ts[prev_sample_tkn],\n",
    "                        model.token_to_pose[prev_sample_tkn],\n",
    "                        model.token_to_ts[sample_tkn],\n",
    "                        model.token_to_pose[sample_tkn])\n",
    "            else: # assume its zero\n",
    "                egovel = np.zeros(2)\n",
    "\n",
    "            if not streaming:\n",
    "                sim_cur_time_ms += data_period_ms\n",
    "                sampled_dets[cur_sample_idx] = pred_dicts\n",
    "                exec_times_ms.append(last_exec_time_ms)\n",
    "            else:\n",
    "                # the sampled_dets can be overwritten, which is okay\n",
    "                sim_cur_time_ms += last_exec_time_ms\n",
    "                num_to_forecast = 500 // data_period_ms\n",
    "                future_sample_inds = [(sim_cur_time_ms+(i*data_period_ms))//data_period_ms for i in range(1,num_to_forecast+1)]\n",
    "                future_sample_inds = torch.tensor([ind for ind in future_sample_inds if ind < num_samples]).int()\n",
    "                if forecasting: # NOTE consider the overhead here\n",
    "                    # Forecast for next 500 ms\n",
    "                    time_diffs_sec = (future_sample_inds * data_period_ms - (sim_cur_time_ms - last_exec_time_ms)) * 1e-3\n",
    "                    outp_bboxes_all = move_bounding_boxes(pred_dicts[0]['pred_boxes'], torch.from_numpy(egovel), time_diffs_sec)\n",
    "                    for outp_bboxes, sample_ind_f in zip(outp_bboxes_all, future_sample_inds.tolist()):\n",
    "                        forecasted_pd = {k : pred_dicts[0][k] for k in ('pred_scores', 'pred_labels')}\n",
    "                        forecasted_pd['pred_boxes'] = outp_bboxes\n",
    "                        sampled_dets[sample_ind_f] = [forecasted_pd]\n",
    "                else:\n",
    "                    for sample_ind_f in future_sample_inds.tolist():\n",
    "                        sampled_dets[sample_ind_f] = pred_dicts\n",
    "\n",
    "            if do_res_sched and sim_cur_time_ms >= target_sched_time_ms:\n",
    "                lbl_dist = torch.bincount(pred_dicts[0]['pred_labels'] - 1, minlength=10).float() / 100.0\n",
    "                inp_tensor = torch.tensor(lbl_dist.tolist() + [np.linalg.norm(egovel).item()/15.0], dtype=torch.float).unsqueeze(0)\n",
    "                inp_tensor[torch.isnan(inp_tensor)] = 0.\n",
    "                res_pred_out_buf = res_pred_trt({'objcount_and_egovel': inp_tensor.cuda()},\n",
    "                    res_pred_out_buf) \n",
    "                res_scores = res_pred_out_buf['res_scores'].cpu()\n",
    "                \n",
    "                _, chosen_res = torch.max(res_scores, 1)\n",
    "                model.res_idx = chosen_res.item()\n",
    "                \n",
    "                #NOTE I need to consider the sched time as well and add to sim cur time ms\n",
    "                target_sched_time_ms += sched_period_ms\n",
    "                \n",
    "            resolution_stats[model.res_idx] += 1\n",
    "\n",
    "            #Dynamic scheduling\n",
    "            if streaming:\n",
    "                cur_tail = calc_tail_ms(sim_cur_time_ms, data_period_ms)\n",
    "                pred_finish_time = sim_cur_time_ms + last_exec_time_ms #NOTE I can also use mean exec time\n",
    "                next_tail = calc_tail_ms(pred_finish_time, data_period_ms)\n",
    "                if next_tail < cur_tail:\n",
    "                    # Sleep, extra 1 ms is added to make sure sleep time is enough\n",
    "                    sim_cur_time_ms += data_period_ms - cur_tail + 1\n",
    "\n",
    "                next_sample_idx = int(sim_cur_time_ms / data_period_ms)\n",
    "            else:\n",
    "                next_sample_idx = cur_sample_idx + 1\n",
    "                \n",
    "            if cur_sample_idx == next_sample_idx:\n",
    "                print(f'ERROR, trying to process already processed sample {next_sample_idx}')\n",
    "            \n",
    "            cur_sample_idx = next_sample_idx\n",
    "            bar(cur_sample_idx / num_samples)\n",
    "\n",
    "    if do_res_sched:\n",
    "        model.res_idx = -1\n",
    "    model.print_time_stats()\n",
    "    print('Resolution selection stats:')\n",
    "    print(resolution_stats)\n",
    "\n",
    "    # exec_times_ms = np.full((len(exec_times_ms),), 1.)\n",
    "    if streaming:\n",
    "        exec_times_musec = None\n",
    "    else:\n",
    "        sample_tokens = [model.dataset.infos[i]['token'] for i in range(num_samples)]\n",
    "        exec_times_ms = np.array(exec_times_ms)\n",
    "        exec_times_musec = exec_times_ms * 1000\n",
    "        exec_times_musec = {st:outp_t for st,outp_t in zip(sample_tokens, exec_times_musec)}\n",
    "\n",
    "    # with open(f'tmp_results/detdata_res{model.res_idx}.pkl', 'wb') as f:\n",
    "        # pickle.dump([sampled_dets, exec_times_musec, resolution_stats], f)\n",
    "\n",
    "    print(f'Sampled {len(sampled_dets)} objects')\n",
    "    return sampled_dets, exec_times_musec, resolution_stats\n",
    "\n",
    "def do_eval(sampled_objects, resolution_idx, dataset, exec_times_musec=None, dump_eval_dict=True, loaded_nusc=None):\n",
    "    #Convert them to openpcdet format\n",
    "    os.environ[\"RESOLUTION_IDX\"] = str(model.res_idx)\n",
    "    \n",
    "    det_annos = []\n",
    "    num_ds_elems = len(dataset)\n",
    "    for i in range(num_ds_elems):\n",
    "        data_dict = dataset.get_metadata_dict(i)\n",
    "        for k, v in data_dict.items():\n",
    "            data_dict[k] = [v] # make it a batch dict\n",
    "        # print(i)\n",
    "        pred_dicts = sampled_objects[i]\n",
    "\n",
    "        if pred_dicts is None:\n",
    "            pred_dicts = [{\n",
    "                'pred_boxes': torch.empty((0, 9)),\n",
    "                'pred_scores': torch.empty(0),\n",
    "                'pred_labels': torch.empty(0, dtype=torch.long)\n",
    "            }]\n",
    "        data_dict['final_box_dicts'] = pred_dicts\n",
    "        det_annos += dataset.generate_prediction_dicts(\n",
    "            data_dict, data_dict['final_box_dicts'], dataset.class_names, output_path=None\n",
    "        )\n",
    "\n",
    "    #nusc_annos = {} # not needed but keep it anyway\n",
    "    result_str, result_dict = dataset.evaluation(\n",
    "        det_annos, dataset.class_names,\n",
    "        eval_metric='kitti', #model.model_cfg.POST_PROCESSING.EVAL_METRIC,\n",
    "        output_path='./tmp_results',\n",
    "        boxes_in_global_coords=False,\n",
    "        loaded_nusc=loaded_nusc,\n",
    "        det_elapsed_musec=exec_times_musec\n",
    "    )\n",
    "\n",
    "    if dump_eval_dict:\n",
    "        eval_d = {\n",
    "        'cfg': cfg,\n",
    "        'det_annos': det_annos,\n",
    "        'annos_in_glob_coords': False,\n",
    "        'resolution': resolution_idx\n",
    "        }\n",
    "    \n",
    "        eval_d['result_str'] = result_str\n",
    "    \n",
    "        with open(f'sampled_dets_res{resolution_idx}.pkl', 'wb') as f:\n",
    "            pickle.dump(eval_d, f)\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddfaa6-57c6-463c-bbaa-1bf8bea6f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes import NuScenes\n",
    "\n",
    "dataset_version = 'v1.0-trainval'\n",
    "root_path = \"../data/nuscenes/\" + dataset_version\n",
    "loaded_nusc = NuScenes(version=dataset_version, dataroot=root_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2514a64d-d54d-4bfd-8f58-aba7f054efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(res_pred_utils)\n",
    "# importlib.reload(nuscenes.eval.detection.evaluate)\n",
    "# importlib.reload(nuscenes.utils.data_classes)\n",
    "\n",
    "# Run test\n",
    "resolution_idx = -1\n",
    "streaming = True\n",
    "forecasting = True\n",
    "\n",
    "os.environ[\"FINE_GRAINED_EVAL\"] = \"0\"\n",
    "model = build_model()\n",
    "sampled_objects, exec_times_musec, resolution_stats = run_test(model, resolution_idx, loaded_nusc,\n",
    "                            streaming=streaming, forecasting=forecasting, sched_period_ms=2000)\n",
    "result_str = do_eval(sampled_objects, resolution_idx, model.dataset, exec_times_musec=exec_times_musec,\n",
    "                             dump_eval_dict=False, loaded_nusc=loaded_nusc)\n",
    "print(result_str)\n",
    "\n",
    "if False:\n",
    "    streaming = True\n",
    "    offline = not streaming\n",
    "    results = []\n",
    "    num_res = 5\n",
    "    for forecasting in (True,): # True):\n",
    "        # os.environ[\"FINE_GRAINED_EVAL\"] = \"1\" if forecasting else \"0\"\n",
    "        # with concurrent.futures.ProcessPoolExecutor(max_workers=num_res, mp_context=mp_context) as executor:\n",
    "            for resolution_idx in range(num_res):\n",
    "                model = build_model()\n",
    "                sampled_objects, exec_times_musec, resolution_stats = run_test(model, resolution_idx, \n",
    "                                                                            loaded_nusc, streaming=streaming, \n",
    "                                                                            forecasting=forecasting, sched_period_ms=2000)\n",
    "\n",
    "                # with open(f'tmp_results/detdata_res{model.res_idx}.pkl', 'rb') as f:\n",
    "                    # sampled_objects, exec_times_musec, resolution_stats = pickle.load(f)\n",
    "                    # print(f'Loaded {len(sampled_objects)} objects from file.')\n",
    "\n",
    "                exec_times_musec = None if (streaming or offline) else exec_times_musec\n",
    "                # fut = executor.submit(\n",
    "                result_str = do_eval(sampled_objects, resolution_idx, model.dataset, exec_times_musec=exec_times_musec,\n",
    "                                     dump_eval_dict=True, loaded_nusc=loaded_nusc)\n",
    "                results.append([resolution_idx, forecasting, resolution_stats, result_str])\n",
    "            # for r in range(1, num_res+1):\n",
    "                result = results[-1]\n",
    "                # result[3] = result[3].result()\n",
    "                print(f'Resolution index: {result[0]}')\n",
    "                print(f'Forecasting: {forecasting}')\n",
    "                print(f'Resolution stats: {result[2]}')\n",
    "                print(result[3])\n",
    "    \n",
    "    with open(f\"output_streaming_{streaming}.txt\", \"w\") as f:\n",
    "        for resolution_idx, forecasting, resolution_stats, result_str in results:\n",
    "            if forecasting:\n",
    "                f.write('FORECASTING WAS UTILIZED\\n')\n",
    "            f.write(f'{resolution_stats}\\n')\n",
    "            f.write(result_str)\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
